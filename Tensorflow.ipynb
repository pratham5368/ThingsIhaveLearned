{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhFjnekp85WknRldJzT4QB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratham5368/ThingsIhaveLearned/blob/main/Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5u3a4csUPyn"
      },
      "source": [
        "#TensorFlow 2.0 Introduction\n",
        "In this notebook you will be given an interactive introduction to TensorFlow 2.0. We will walk through the following topics within the TensorFlow module:\n",
        "\n",
        "- TensorFlow Install and Setup\n",
        "- Representing Tensors\n",
        "- Tensor Shape and Rank\n",
        "- Types of Tensors\n",
        "\n",
        "\n",
        "If you'd like to follow along without installing TensorFlow on your machine you can use **Google Collaboratory**. Collaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7ThfbiQl96l"
      },
      "source": [
        "##Installing TensorFlow\n",
        "To install TensorFlow on your local machine you can use pip.\n",
        "```console\n",
        "pip install tensorflow\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYQWyAJ2mez6"
      },
      "source": [
        "![alt text](https://)If you have a CUDA enabled GPU you can install the GPU version of TensorFlow. You will also need to install some other software which can be found here: https://www.tensorflow.org/install/gpu\n",
        "```console\n",
        "pip install tensorflow-gpu\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJjNMaSClWhg"
      },
      "source": [
        "## Importing TensorFlow\n",
        "The first step here is going to be to select the correct version of TensorFlow from within collabratory!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGcE8x2Gkw9K"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N7XbNDVY8P3"
      },
      "source": [
        "import tensorflow as tf  # now import the tensorflow module\n",
        "print(tf.version)  # make sure the version is 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duDj86TfWFof"
      },
      "source": [
        "##Tensors\n",
        "\"A tensor is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes.\" (https://www.tensorflow.org/guide/tensor)\n",
        "\n",
        "They are multi-dimensional arrays that can hold numerical data of various types, such as integers, floats, and booleans.\n",
        "\n",
        "\n",
        "\n",
        "It should't surprise you that tensors are a fundemental apsect of TensorFlow. They are the main objects that are passed around and manipluated throughout the program. Each tensor represents a partialy defined computation that will eventually produce a value. TensorFlow programs work by building a graph of Tensor objects that details how tensors are related. Running different parts of the graph allow results to be generated.\n",
        "\n",
        "Each tensor has a data type and a shape.\n",
        "\n",
        "**Data Types Include**: float32, int32, string and others.\n",
        "\n",
        "**Shape**: Represents the dimension of data.\n",
        "\n",
        "Just like vectors and matrices tensors can have operations applied to them like addition, subtraction, dot product, cross product etc.\n",
        "\n",
        "In the next sections we will discuss some different properties of tensors. This is to make you more familiar with how tensorflow represnts data and how you can manipulate this data.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a simple tensor\n",
        "tensor_A = tf.constant([1, 2, 3])\n"
      ],
      "metadata": {
        "id": "vrJDl0ep7acA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAk6QhGUwQRt"
      },
      "source": [
        "###Creating Tensors\n",
        "\n",
        "> Indented block\n",
        "\n",
        "# > Indented block\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Below is an example of how to create some different tensors.\n",
        "\n",
        "You simply define the value of the tensor and the datatype and you are good to go! It's worth mentioning that usually we deal with tensors of numeric data, it is quite rare to see string tensors.\n",
        "\n",
        "For a full list of datatypes please refer to the following guide.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/dtypes/DType?version=stable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epGskXdjZHzu"
      },
      "source": [
        "string = tf.Variable(\"this is a string\", tf.string)\n",
        "number = tf.Variable(324, tf.int16)\n",
        "floating = tf.Variable(3.567, tf.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0_H71HMaE-5"
      },
      "source": [
        "###Rank/Degree of Tensors\n",
        "Another word for rank is degree, these terms simply mean the number of dimensions involved in the tensor. What we created above is a *tensor of rank 0*, also known as a scalar.\n",
        "```tf.rank``` — How many dimensions are in the tensor?\n",
        "\n",
        "Now we'll create some tensors of higher degrees/ranks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX_Cc5IfjQ6-"
      },
      "source": [
        "rank1_tensor = tf.Variable([\"Test\"], tf.string)\n",
        "rank2_tensor = tf.Variable([[\"test\", \"ok\"], [\"test\", \"yes\"]], tf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55zuGMc7nHjC"
      },
      "source": [
        "**To determine the rank** of a tensor we can call the following method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrj0rAWLnMNv",
        "outputId": "b8b34a8c-fc6e-40c6-9fd6-294d1253631e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.rank(rank2_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTv4Gz67pQbx"
      },
      "source": [
        "The rank of a tensor is direclty related to the deepest level of nested lists. You can see in the first example ```[\"Test\"]``` is a rank 1 tensor as the deepest level of nesting is 1.\n",
        "Where in the second example ```[[\"test\", \"ok\"], [\"test\", \"yes\"]]``` is a rank 2 tensor as the deepest level of nesting is 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaVrANK8q21q"
      },
      "source": [
        "###Shape of Tensors\n",
        "Now that we've talked about the rank of tensors it's time to talk about the shape. The shape of a tensor is simply the number of elements that exist in each dimension. TensorFlow will try to determine the shape of a tensor but sometimes it may be unknown.```tf.shape``` — What are the dimensions/shape of the tensor?\n",
        "\n",
        "To **get the shape** of a tensor we use the shape attribute.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_NRXsFOraYa"
      },
      "source": [
        "rank2_tensor.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVDmLJeFs086"
      },
      "source": [
        "###Changing Shape\n",
        "The number of elements of a tensor is the product of the sizes of all its shapes. There are often many shapes that have the same number of elements, making it convient to be able to change the shape of a tensor.\n",
        "\n",
        "\n",
        "\n",
        "The example below shows how to change the shape of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ8Rbs2xtNqj"
      },
      "source": [
        "tensor1 = tf.ones([1,2,3])  # tf.ones() creates a shape [1,2,3] tensor full of ones\n",
        "tensor2 = tf.reshape(tensor1, [2,3,1])  # reshape existing data to shape [2,3,1]\n",
        "tensor3 = tf.reshape(tensor2, [3, -1])  # -1 tells the tensor to calculate the size of the dimension in that place\n",
        "                                        # this will reshape the tensor to [3,3]\n",
        "\n",
        "# The numer of elements in the reshaped tensor MUST match the number in the original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M631k7UDv1Wh"
      },
      "source": [
        "Now let's have a look at our different tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFNmUxaEv6s3"
      },
      "source": [
        "print(tensor1)\n",
        "print(tensor2)\n",
        "print(tensor3)\n",
        "# Notice the changes in shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Size\n",
        "```tf.shape``` — What are the dimensions/shape of the tensor?"
      ],
      "metadata": {
        "id": "BXw8fZOHjbrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many elements are in the tensor? (e.g. 224*224*3 = 150528)\n",
        "tensor_size = tf.size(tensor)\n"
      ],
      "metadata": {
        "id": "LGRkNCK3jmfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q88pJucBolsp"
      },
      "source": [
        "###Slicing Tensors\n",
        "You may be familiar with the term \"slice\" in python and its use on lists, tuples etc. Well the slice operator can be used on tensors to select specific axes or elements.\n",
        "\n",
        "When we slice or select elements from a tensor, we can use comma seperated values inside the set of square brackets. Each subsequent value refrences a different dimension of the tensor.\n",
        "\n",
        "Ex: ```tensor[dim1, dim2, dim3]```\n",
        "\n",
        "I've included a few examples that will hopefully help illustrate how we can manipulate tensors with the slice operator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0YrD-hRqD-W"
      },
      "source": [
        "# Creating a 2D tensor\n",
        "matrix = [[1,2,3,4,5],\n",
        "          [6,7,8,9,10],\n",
        "          [11,12,13,14,15],\n",
        "          [16,17,18,19,20]]\n",
        "\n",
        "tensor = tf.Variable(matrix, dtype=tf.int32)\n",
        "print(tf.rank(tensor))\n",
        "print(tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd85uGI7qyfC"
      },
      "source": [
        "# Now lets select some different rows and columns from our tensor\n",
        "\n",
        "three = tensor[0,2]  # selects the 3rd element from the 1st row\n",
        "print(three)  # -> 3\n",
        "\n",
        "row1 = tensor[0]  # selects the first row\n",
        "print(row1)\n",
        "\n",
        "column1 = tensor[:, 0]  # selects the first column\n",
        "print(column1)\n",
        "\n",
        "row_2_and_4 = tensor[1::2]  # selects second and fourth row\n",
        "print(row2and4)\n",
        "\n",
        "column_1_in_row_2_and_3 = tensor[1:3, 0]\n",
        "print(column_1_in_row_2_and_3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU4MMhB_rxvz"
      },
      "source": [
        "###Types of Tensors\n",
        "Before we go to far, I will mention that there are diffent types of tensors. These are the most used and we will talk more in depth about each as they are used.\n",
        "- Variable\n",
        "- Constant\n",
        "- Placeholder\n",
        "- SparseTensor\n",
        "\n",
        "With the execption of ```Variable``` all these tensors are immuttable, meaning their value may not change during execution.\n",
        "\n",
        "For now, it is enough to understand that we use the Variable tensor when we want to potentially change the value of our tensor.\n",
        "\n",
        "Variables are tensors that can be modified during model training.\n",
        "\n",
        "They are used to represent neural network model parameters, such as weights and biases.\n",
        "\n",
        "These parameters can then be adjusted to better represent data.\n",
        "\n",
        "For example, your tensors may start with random values to begin with but during training these random values get changed to be more aligned with ideal values that represent your data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Variables\n",
        "Variable tensors are mutable (changable) tensors that store weights and biases in neural networks.\n",
        "\n",
        "These are updated during neural network training to better represent the data a model is training on.\n",
        "\n",
        "They can be created with ```tf.Variable```:"
      ],
      "metadata": {
        "id": "nvNvmbqej_-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = tf.Variable(initial_value)"
      ],
      "metadata": {
        "id": "xwjlkiVDkLbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GradientTape\n",
        "You can use ```tf.GradientTape``` to record operations on variables for automatic differentiation.\n",
        "\n",
        "This is helpful for creating your own training loops with TensorFlow:\n",
        "\n"
      ],
      "metadata": {
        "id": "Fh7H51EFkUfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    # Operations involving variables\n",
        "\t\tgradients = tape.gradient(loss, [list_of_variables])\n"
      ],
      "metadata": {
        "id": "mfVnvrJakfdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Basic Math Operations\n",
        "TensorFlow includes options for performing element-wise addition, subtraction, multiplication, and division:"
      ],
      "metadata": {
        "id": "Vt0EDk0djvoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "addition = tf.add(a, b)\n",
        "subtraction = tf.subtract(a, b)\n",
        "multiplication = tf.multiply(a, b)\n",
        "division = tf.divide(a, b)\n"
      ],
      "metadata": {
        "id": "rQhLxFlHju94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2OoXbe7aSVl"
      },
      "source": [
        "#Sources\n",
        "Most of the information is taken direclty from the TensorFlow website which can be found below.\n",
        "\n",
        "https://www.tensorflow.org/guide/tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUgsCvCHLksw"
      },
      "source": [
        "#TensorFlow Core Learning Algorithms\n",
        "In this notebook we will walk through 4 fundemental machine learning algorithms. We will apply each of these algorithms to unique problems and datasets before highlighting the use cases of each.\n",
        "\n",
        "The algorithms we will focus on include:\n",
        "- Linear Regression\n",
        "- Classification\n",
        "- Clustering\n",
        "- Hidden Markov Models\n",
        "\n",
        "It is worth noting that there are many tools within TensorFlow that could be used to solve the problems we will see below. I have chosen the tools that I belive give the most variety and are easiest to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbdnKlcuMM4u"
      },
      "source": [
        "##Linear Regression\n",
        "Linear regression is one of the most basic forms of machine learning and is used to predict numeric values.\n",
        "\n",
        "In this tutorial we will use a linear model to predict the survival rate of passangers from the titanic dataset.\n",
        "\n",
        "*This section is based on the following documentation: https://www.tensorflow.org/tutorials/estimator/linear*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsJ-Iov1P4RK"
      },
      "source": [
        "###How it Works\n",
        "Before we dive in, I will provide a very surface level explination of the linear regression algorithm.\n",
        "\n",
        "Linear regression follows a very simple concept. If data points are related linearly, we can generate a line of best fit for these points and use it to predict future values.\n",
        "\n",
        "Let's take an example of a data set with one feature and one label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Hp-dYmR2jf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "db401a27-85b0-4ec2-a110-91c938f54bca"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = [1, 2, 2.5, 3, 4]\n",
        "y = [1, 4, 7, 9, 15]\n",
        "plt.plot(x, y, 'ro')\n",
        "plt.axis([0, 6, 0, 20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 6.0, 0.0, 20.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m1DTp22SLo3"
      },
      "source": [
        "We can see that this data has a linear coorespondence. When the x value increases, so does the y. Because of this relation we can create a line of best fit for this dataset. In this example our line will only use one input variable, as we are working with two dimensions. In larger datasets with more features our line will have more features and inputs.\n",
        "\n",
        "\"Line of best fit refers to a line through a scatter plot of data points that best expresses the relationship between those points.\" (https://www.investopedia.com/terms/l/line-of-best-fit.asp)\n",
        "\n",
        "Here's a refresher on the equation of a line in 2D.\n",
        "\n",
        "$ y = mx + b $\n",
        "\n",
        "Here's an example of a line of best fit for this graph.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv5eKLP_UYZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "77c4f7fd-d343-4f60-a7a0-ebeecd253ef9"
      },
      "source": [
        "plt.plot(x, y, 'ro')\n",
        "plt.axis([0, 6, 0, 20])\n",
        "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd3T50PLB4lV"
      },
      "source": [
        "Once we've generated this line for our dataset, we can use its equation to predict future values. We just pass the features of the data point we would like to predict into the equation of the line and use the output as our prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y02FbC56Nbx0"
      },
      "source": [
        "### Setup and Imports\n",
        "Before we get started we must install *sklearn* and import the following modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4xpuxwKHOGL"
      },
      "source": [
        "!pip install -q sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI3zi2ZhQ3WB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "9b7fa093-1a82-481a-fabe-1cb44429919d"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcII_xj9Ntyo"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GltdTjiERfWi"
      },
      "source": [
        "### Data\n",
        "So, if you haven't realized by now a major part of machine learning is data! In fact, it's so important that most of what we do in this tutorial will focus on exploring, cleaning and selecting appropriate data.\n",
        "\n",
        "The dataset we will be focusing on here is the titanic dataset. It has tons of information about each passanger on the ship. Our first step is always to understand the data and explore it. So, let's do that!\n",
        "\n",
        "**Below we will load a dataset and learn how we can explore it using some built-in tools. **\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpllWsKIOGOy"
      },
      "source": [
        "# Load dataset.\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PJr5GosQBeY"
      },
      "source": [
        "The ```pd.read_csv()``` method will return to us a new pandas *dataframe*. You can think of a dataframe like a table. In fact, we can actually have a look at the table representation.\n",
        "\n",
        "We've decided to pop the \"survived\" column from our dataset and store it in a new variable. This column simply tells us if the person survived our not.\n",
        "\n",
        "To look at the data we'll use the ```.head()``` method from pandas. This will show us the first 5 items in our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKsXeWinQiVR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "b91f8b23-eb7b-4fa6-ccd7-aef6d9441afa"
      },
      "source": [
        "dftrain.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sex   age  n_siblings_spouses  parch  ...  class     deck  embark_town alone\n",
              "0    male  22.0                   1      0  ...  Third  unknown  Southampton     n\n",
              "1  female  38.0                   1      0  ...  First        C    Cherbourg     n\n",
              "2  female  26.0                   0      0  ...  Third  unknown  Southampton     y\n",
              "3  female  35.0                   1      0  ...  First        C  Southampton     n\n",
              "4    male  28.0                   0      0  ...  Third  unknown   Queenstown     y\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeVQGdpCRC1P"
      },
      "source": [
        "And if we want a more statistical analysis of our data we can use the ```.describe()``` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkL2G42GRMf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "ffb42606-8f18-48d2-aacf-120578212af7"
      },
      "source": [
        "dftrain.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX7FSzrQRXeC"
      },
      "source": [
        "And since we talked so much about shapes in the previous tutorial let's have a look at that too!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR1Oy1dISdjn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94fb254b-0222-4b4b-d47c-73562f37571c"
      },
      "source": [
        "dftrain.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(627, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIfLiSRMTeW4"
      },
      "source": [
        "So have have 627 entries and 9 features, nice!\n",
        "\n",
        "Now let's have a look at our survival information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX1lKW7TTh-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "6b2efa46-40a8-4fae-bdd1-b828283daa0c"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    0\n",
              "Name: survived, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahqIyYPoTnRh"
      },
      "source": [
        "Notice that each entry is either a 0 or 1. Can you guess which stands for survival?\n",
        "\n",
        "**And now because visuals are always valuable let's generate a few graphs of the data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edndbw4sU5Wd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "42a09890-5513-4785-84d7-98af53216446"
      },
      "source": [
        "dftrain.age.hist(bins=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f680f2b4d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SM_tYvyUtsw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "128bea12-3654-4692-e7cc-6279f8ed2079"
      },
      "source": [
        "dftrain.sex.value_counts().plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f680f1bf400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCv3ek2LU1Lw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a71bfdd1-ebbf-44cf-ad1b-9ec992e2fcd7"
      },
      "source": [
        "dftrain['class'].value_counts().plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f680f185b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4kPWqBYVDlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "c4f858de-73e4-41a3-8928-e97a0e0e08ad"
      },
      "source": [
        "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, '% survive')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l42qmk_bVHvD"
      },
      "source": [
        "After analyzing this information, we should notice the following:\n",
        "- Most passengers are in their 20's or 30's\n",
        "- Most passengers are male\n",
        "- Most passengers are in \"Third\" class\n",
        "- Females have a much higher chance of survival\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIBZww6kOIAp"
      },
      "source": [
        "### Training vs Testing Data\n",
        "You may have noticed that we loaded **two different datasets** above. This is because when we train models, we need two sets of data: **training and testing**.\n",
        "\n",
        "The **training** data is what we feed to the model so that it can develop and learn. It is usually a much larger size than the testing data.\n",
        "\n",
        "The **testing** data is what we use to evaulate the model and see how well it is performing. We must use a seperate set of data that the model has not been trained on to evaluate it. Can you think of why this is?\n",
        "\n",
        "Well, the point of our model is to be able to make predictions on NEW data, data that we have never seen before. If we simply test the model on the data that it has already seen we cannot measure its accuracy accuratly. We can't be sure that the model hasn't simply memorized our training data. This is why we need our testing and training data to be seperate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar_cXv2jV8A3"
      },
      "source": [
        "###Feature Columns\n",
        "In our dataset we have two different kinds of information: **Categorical and Numeric**\n",
        "\n",
        "Our **categorical data** is anything that is not numeric! For example, the sex column does not use numbers, it uses the words \"male\" and \"female\".\n",
        "\n",
        "Before we continue and create/train a model we must convet our categorical data into numeric data. We can do this by encoding each category with an integer (ex. male = 1, female = 2).\n",
        "\n",
        "Fortunately for us TensorFlow has some tools to help!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lcnwG0VXF5h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a4603a14-5903-4e75-a8cf-6a2ccca69946"
      },
      "source": [
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
        "                       'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age', 'fare']\n",
        "\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
        "\n",
        "print(feature_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-nazdZpXgAr"
      },
      "source": [
        "Let's break this code down a little bit...\n",
        "\n",
        "Essentially what we are doing here is creating a list of features that are used in our dataset.\n",
        "\n",
        "The cryptic lines of code inside the ```append()``` create an object that our model can use to map string values like \"male\" and \"female\" to integers. This allows us to avoid manually having to encode our dataframes.\n",
        "\n",
        "*And here is some relevant documentation*\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list?version=stable\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQlXWErlbhsG"
      },
      "source": [
        "###The Training Process\n",
        "So, we are almost done preparing our dataset and I feel as though it's a good time to explain how our model is trained. Specifically, how input data is fed to our model.\n",
        "\n",
        "For this specific model data is going to be streamed into it in small batches of 32. This means we will not feed the entire dataset to our model at once, but simply small batches of entries. We will feed these batches to our model multiple times according to the number of **epochs**.\n",
        "\n",
        "An **epoch** is simply one stream of our entire dataset. The number of epochs we define is the amount of times our model will see the entire dataset. We use multiple epochs in hope that after seeing the same data multiple times the model will better determine how to estimate it.\n",
        "\n",
        "Ex. if we have 10 ephocs, our model will see the same dataset 10 times.\n",
        "\n",
        "Since we need to feed our data in batches and multiple times, we need to create something called an **input function**. The input function simply defines how our dataset will be converted into batches at each epoch.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO0mBu_WaVXp"
      },
      "source": [
        "###Input Function\n",
        "The TensorFlow model we are going to use requires that the data we pass it comes in as a ```tf.data.Dataset``` object. This means we must create a *input function* that can convert our current pandas dataframe into that object.\n",
        "\n",
        "Below you'll see a seemingly complicated input function, this is straight from the TensorFlow documentation (https://www.tensorflow.org/tutorials/estimator/linear). I've commented as much as I can to make it understandble, but you may want to refer to the documentation for a detailed explination of each method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3qcbvOYbIwa"
      },
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():  # inner function, this will be returned\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)  # randomize order of data\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "    return ds  # return a batch of the dataset\n",
        "  return input_function  # return a function object for use\n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXqlPst9fpx4"
      },
      "source": [
        "###Creating the Model\n",
        "In this tutorial we are going to use a linear estimator to utilize the linear regression algorithm.\n",
        "\n",
        "Creating one is pretty easy! Have a look below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Wo8brFf663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "73b78e55-1fc4-44b0-9fc6-33506a199db5"
      },
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "# We create a linear estimtor by passing the feature columns we created earlier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpupqmt1yp\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpupqmt1yp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5GPkW_CgDFy"
      },
      "source": [
        "###Training the Model\n",
        "Training the model is as easy as passing the input functions that we created earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J11OJrlZgPhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd3c7099-fdde-45aa-b57b-f1c8d1d02024"
      },
      "source": [
        "linear_est.train(train_input_fn)  # train\n",
        "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n",
        "\n",
        "clear_output()  # clears consoke output\n",
        "print(result['accuracy'])  # the result variable is simply a dict of stats about our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7689394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LisxO81tgi1n"
      },
      "source": [
        "And we now we have a model with a 74% accuracy (this will change each time)! Not crazy impressive but decent for our first try.\n",
        "\n",
        "Now let's see how we can actually use this model to make predicitons.\n",
        "\n",
        "We can use the ```.predict()``` method to get survival probabilities from the model. This method will return a list of dicts that store a predicition for each of the entries in our testing data set. Below we've used some pandas magic to plot a nice graph of the predictions.\n",
        "\n",
        "As you can see the survival rate is not very high :/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQz0Lj60hjLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "eec262fd-e206-46b6-d8d7-7c9067546f16"
      },
      "source": [
        "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
        "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
        "\n",
        "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpupqmt1yp/model.ckpt-200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6807c6ac18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG9gxhAqVTBT"
      },
      "source": [
        "##Classification\n",
        "Now that we've covered linear regression it is time to talk about classification. Where regression was used to predict a numeric value, classification is used to seperate data points into classes of different labels. In this example we will use a TensorFlow estimator to classify flowers.\n",
        "\n",
        "Since we've touched on how estimators work earlier, I'll go a bit quicker through this example.\n",
        "\n",
        "This section is based on the following guide from the TensorFlow website.\n",
        "https://www.tensorflow.org/tutorials/estimator/premade\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWk2Kb7Sdk-T"
      },
      "source": [
        "###Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH4_xJaD605_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "cbe50069-f9c1-489e-ebdb-e08af4d7cea5"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMiLc6LPdoPm"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zLNzmkGds1U"
      },
      "source": [
        "###Dataset\n",
        "This specific dataset seperates flowers into 3 different classes of species.\n",
        "- Setosa\n",
        "- Versicolor\n",
        "- Virginica\n",
        "\n",
        "The information about each flower is the following.\n",
        "- sepal length\n",
        "- sepal width\n",
        "- petal length\n",
        "- petal width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puOQDTNKeCRC"
      },
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "# Lets define some constants to help us later on"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMW41Wd9eLIo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "4950908e-de50-4839-a569-a1f5acf015f8"
      },
      "source": [
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
            "8192/2194 [================================================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
            "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHRWY47ecdr"
      },
      "source": [
        "Let's have a look at our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ9uo6KkegBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "ed4b9d06-06da-4014-f04d-95bc35dc64ba"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
              "0          6.4         2.8          5.6         2.2        2\n",
              "1          5.0         2.3          3.3         1.0        1\n",
              "2          4.9         2.5          4.5         1.7        2\n",
              "3          4.9         3.1          1.5         0.1        0\n",
              "4          5.7         3.8          1.7         0.3        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PzWyoE9eu8H"
      },
      "source": [
        "Now we can pop the species column off and use that as our label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP_nlslke4U8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "560a0559-ebf8-43a8-bca7-4fa25d9c06ce"
      },
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')\n",
        "train.head() # the species column is now gone"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          6.4         2.8          5.6         2.2\n",
              "1          5.0         2.3          3.3         1.0\n",
              "2          4.9         2.5          4.5         1.7\n",
              "3          4.9         3.1          1.5         0.1\n",
              "4          5.7         3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oVw2zRkfTXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a25c814d-63e4-40da-9ac9-6efc326164b2"
      },
      "source": [
        "train.shape  # we have 120 entires with 4 features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6ZWVZs8fg-H"
      },
      "source": [
        "###Input Function\n",
        "Remember that nasty input function we created earlier. Well we need to make another one here! Fortunatly for us this one is a little easier to digest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-NQRLv_fyhg"
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "    return dataset.batch(batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL--3OAnf4mO"
      },
      "source": [
        "###Feature Columns\n",
        "And you didn't think we forgot about the feature columns, did you?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nErIJJbggQ5w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "837852b1-97a0-4965-88fc-50883dfb558c"
      },
      "source": [
        "# Feature columns describe how to use the input.\n",
        "my_feature_columns = []\n",
        "for key in train.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(my_feature_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kl1Wr_Xgpmv"
      },
      "source": [
        "###Building the Model\n",
        "And now we are ready to choose a model. For classification tasks there are variety of different estimators/models that we can pick from. Some options are listed below.\n",
        "- ```DNNClassifier``` (Deep Neural Network)\n",
        "- ```LinearClassifier```\n",
        "\n",
        "We can choose either model but the DNN seems to be the best choice. This is because we may not be able to find a linear coorespondence in our data.\n",
        "\n",
        "So let's build a model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7YVQowgiDak",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "bd9457f3-7d30-456c-aa8b-3d160c0f751f"
      },
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\n",
        "    hidden_units=[30, 10],\n",
        "    # The model must choose between 3 classes.\n",
        "    n_classes=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqaqtrlgy\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpqaqtrlgy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ_SJAMuiF6p"
      },
      "source": [
        "What we've just done is created a deep neural network that has two hidden layers. These layers have 30 and 10 neurons respectively. This is the number of neurons the TensorFlow official tutorial uses so we'll stick with it. However, it is worth mentioning that the number of hidden neurons is an arbitrary number and many experiments and tests are usually done to determine the best choice for these values. Try playing around with the number of hidden neurons and see if your results change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBHnWYKTjV5D"
      },
      "source": [
        "###Training\n",
        "Now it's time to train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INug63pCjaOw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3eb6211c-9fd1-4748-8e2e-31e64b4ec698"
      },
      "source": [
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps=5000)\n",
        "# We include a lambda to avoid creating an inner function previously"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpqaqtrlgy/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 1.1511875, step = 0\n",
            "INFO:tensorflow:global_step/sec: 497.034\n",
            "INFO:tensorflow:loss = 0.9358924, step = 100 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.632\n",
            "INFO:tensorflow:loss = 0.90521353, step = 200 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.875\n",
            "INFO:tensorflow:loss = 0.8495918, step = 300 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.748\n",
            "INFO:tensorflow:loss = 0.82983136, step = 400 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.704\n",
            "INFO:tensorflow:loss = 0.7790096, step = 500 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.452\n",
            "INFO:tensorflow:loss = 0.7574419, step = 600 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.438\n",
            "INFO:tensorflow:loss = 0.7266582, step = 700 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.098\n",
            "INFO:tensorflow:loss = 0.7117815, step = 800 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.401\n",
            "INFO:tensorflow:loss = 0.6849373, step = 900 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.227\n",
            "INFO:tensorflow:loss = 0.6696919, step = 1000 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.756\n",
            "INFO:tensorflow:loss = 0.6453049, step = 1100 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.265\n",
            "INFO:tensorflow:loss = 0.63444245, step = 1200 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.941\n",
            "INFO:tensorflow:loss = 0.61837286, step = 1300 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.566\n",
            "INFO:tensorflow:loss = 0.60927534, step = 1400 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.653\n",
            "INFO:tensorflow:loss = 0.59321785, step = 1500 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.728\n",
            "INFO:tensorflow:loss = 0.5786046, step = 1600 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.974\n",
            "INFO:tensorflow:loss = 0.5679003, step = 1700 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.473\n",
            "INFO:tensorflow:loss = 0.55420506, step = 1800 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.02\n",
            "INFO:tensorflow:loss = 0.51620936, step = 1900 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.192\n",
            "INFO:tensorflow:loss = 0.5385388, step = 2000 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.724\n",
            "INFO:tensorflow:loss = 0.523809, step = 2100 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.861\n",
            "INFO:tensorflow:loss = 0.50772285, step = 2200 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.258\n",
            "INFO:tensorflow:loss = 0.49664536, step = 2300 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.988\n",
            "INFO:tensorflow:loss = 0.49152842, step = 2400 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.346\n",
            "INFO:tensorflow:loss = 0.4791621, step = 2500 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.166\n",
            "INFO:tensorflow:loss = 0.46931824, step = 2600 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.973\n",
            "INFO:tensorflow:loss = 0.46762398, step = 2700 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.066\n",
            "INFO:tensorflow:loss = 0.44671822, step = 2800 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.873\n",
            "INFO:tensorflow:loss = 0.44892073, step = 2900 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.968\n",
            "INFO:tensorflow:loss = 0.44627833, step = 3000 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.9\n",
            "INFO:tensorflow:loss = 0.4288814, step = 3100 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.251\n",
            "INFO:tensorflow:loss = 0.43346274, step = 3200 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.476\n",
            "INFO:tensorflow:loss = 0.42365474, step = 3300 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.291\n",
            "INFO:tensorflow:loss = 0.41678685, step = 3400 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.509\n",
            "INFO:tensorflow:loss = 0.41475928, step = 3500 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.669\n",
            "INFO:tensorflow:loss = 0.40962964, step = 3600 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.631\n",
            "INFO:tensorflow:loss = 0.40175164, step = 3700 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.225\n",
            "INFO:tensorflow:loss = 0.39052343, step = 3800 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.891\n",
            "INFO:tensorflow:loss = 0.39769873, step = 3900 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.438\n",
            "INFO:tensorflow:loss = 0.386145, step = 4000 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.811\n",
            "INFO:tensorflow:loss = 0.39405277, step = 4100 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.425\n",
            "INFO:tensorflow:loss = 0.37922394, step = 4200 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.11\n",
            "INFO:tensorflow:loss = 0.37118322, step = 4300 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.221\n",
            "INFO:tensorflow:loss = 0.36706787, step = 4400 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 681.885\n",
            "INFO:tensorflow:loss = 0.3653447, step = 4500 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.826\n",
            "INFO:tensorflow:loss = 0.3557425, step = 4600 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.897\n",
            "INFO:tensorflow:loss = 0.36362734, step = 4700 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.864\n",
            "INFO:tensorflow:loss = 0.3526679, step = 4800 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.965\n",
            "INFO:tensorflow:loss = 0.35308143, step = 4900 (0.151 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpqaqtrlgy/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.34763944.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f6807b4ca20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5suI1lmskE7p"
      },
      "source": [
        "###Evaluation\n",
        "Now let's see how this trained model does!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23rIrgbxkJUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "24767659-81cb-436f-a3c5-3fb19fcf53b2"
      },
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-06-19T18:22:07Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpqaqtrlgy/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.20221s\n",
            "INFO:tensorflow:Finished evaluation at 2020-06-19-18:22:08\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.93333334, average_loss = 0.41360682, global_step = 5000, loss = 0.41360682\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpqaqtrlgy/model.ckpt-5000\n",
            "\n",
            "Test set accuracy: 0.933\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "464HkZ6lknua"
      },
      "source": [
        "### Predictions\n",
        "Now that we have a trained model it's time to use it to make predictions. I've written a little script below that allows you to type the features of a flower and see a prediction for its class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQRLq4M1k1jm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "f720852e-66e9-448e-bddf-ce33ce98cc61"
      },
      "source": [
        "def input_fn(features, batch_size=256):\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
        "predict = {}\n",
        "\n",
        "print(\"Please type numeric values as prompted.\")\n",
        "for feature in features:\n",
        "  valid = True\n",
        "  while valid:\n",
        "    val = input(feature + \": \")\n",
        "    if not val.isdigit(): valid = False\n",
        "\n",
        "  predict[feature] = [float(val)]\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type numeric values as prompted.\n",
            "SepalLength: 23\n",
            "SepalLength: 12\n",
            "SepalLength: 12\n",
            "SepalLength: 3\n",
            "SepalLength: 4\n",
            "SepalLength: 2\n",
            "SepalLength: 0.5\n",
            "SepalWidth: 2\n",
            "SepalWidth: 0.4\n",
            "PetalLength: 0.5\n",
            "PetalWidth: 0.3\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpqaqtrlgy/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Setosa\" (38.2%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tRxhpmSr1FH"
      },
      "source": [
        "# Here is some example input and expected classes you can try above\n",
        "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
        "predict_x = {\n",
        "    'SepalLength': [5.1, 5.9, 6.9],\n",
        "    'SepalWidth': [3.3, 3.0, 3.1],\n",
        "    'PetalLength': [1.7, 4.2, 5.4],\n",
        "    'PetalWidth': [0.5, 1.5, 2.1],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0dfaT4esRh3"
      },
      "source": [
        "##Clustering\n",
        "Now that we've covered regression and classification it's time to talk about clustering data!\n",
        "\n",
        "Clustering is a Machine Learning technique that involves the grouping of data points. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. (https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68)\n",
        "\n",
        "Unfortunalty there are issues with the current version of TensorFlow and the implementation for KMeans. This means we cannot use KMeans without writing the algorithm from scratch. We aren't quite at that level yet, so we'll just explain the basics of clustering for now.\n",
        "\n",
        "####Basic Algorithm for K-Means.\n",
        "- Step 1: Randomly pick K points to place K centroids\n",
        "- Step 2: Assign all the data points to the centroids by distance. The closest centroid to a point is the one it is assigned to.\n",
        "- Step 3: Average all the points belonging to each centroid to find the middle of those clusters (center of mass). Place the corresponding centroids into that position.\n",
        "- Step 4: Reassign every point once again to the closest centroid.\n",
        "- Step 5: Repeat steps 3-4 until no point changes which centroid it belongs to.\n",
        "\n",
        "*Please refer to the video for an explanation of KMeans clustering.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ9iJrSbBTZB"
      },
      "source": [
        "##Hidden Markov Models\n",
        "\n",
        "\"The Hidden Markov Model is a finite set of states, each of which is associated with a (generally multidimensional) probability distribution []. Transitions among the states are governed by a set of probabilities called transition probabilities.\" (http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html)\n",
        "\n",
        "A hidden markov model works with probabilities to predict future events or states. In this section we will learn how to create a hidden markov model that can predict the weather.\n",
        "\n",
        "*This section is based on the following TensorFlow tutorial.* https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKJSFk4NP0eq"
      },
      "source": [
        "###Data\n",
        "Let's start by discussing the type of data we use when we work with a hidden markov model.\n",
        "\n",
        "In the previous sections we worked with large datasets of 100's of different entries. For a markov model we are only interested in probability distributions that have to do with states.\n",
        "\n",
        "We can find these probabilities from large datasets or may already have these values. We'll run through an example in a second that should clear some things up, but let's discuss the components of a markov model.\n",
        "\n",
        "**States:** In each markov model we have a finite set of states. These states could be something like \"warm\" and \"cold\" or \"high\" and \"low\" or even \"red\", \"green\" and \"blue\". These states are \"hidden\" within the model, which means we do not direcly observe them.\n",
        "\n",
        "**Observations:** Each state has a particular outcome or observation associated with it based on a probability distribution. An example of this is the following: *On a hot day Tim has a 80% chance of being happy and a 20% chance of being sad.*\n",
        "\n",
        "**Transitions:** Each state will have a probability defining the likelyhood of transitioning to a different state. An example is the following: *a cold day has a 30% chance of being followed by a hot day and a 70% chance of being follwed by another cold day.*\n",
        "\n",
        "To create a hidden markov model we need.\n",
        "- States\n",
        "- Observation Distribution\n",
        "- Transition Distribution\n",
        "\n",
        "For our purpose we will assume we already have this information available as we attempt to predict the weather on a given day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK2QbOzr6jNJ"
      },
      "source": [
        "###Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suf1v8kJ6niA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "f12c7178-cc43-42cd-92c3-8084d5d61637"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_Fkrx30xbb"
      },
      "source": [
        "Due to a version mismatch with tensorflow v2 and tensorflow_probability we need to install the most recent version of tensorflow_probability (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kawrMHKGBWyS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "ad6d30ff-e53a-4776-825d-c18e2b0728cc"
      },
      "source": [
        "!pip install tensorflow_probability==0.8.0rc0 --user --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_probability==0.8.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/63/f54ce32063abaa682d779e44b49eb63fcf63c2422f978842fdeda794337d/tensorflow_probability-0.8.0rc0-py2.py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability==0.8.0rc0) (4.4.2)\n",
            "Collecting cloudpickle==1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/24/fb/4f92f8c0f40a0d728b4f3d5ec5ff84353e705d8ff5e3e447620ea98b06bd/cloudpickle-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability==0.8.0rc0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability==0.8.0rc0) (1.18.5)\n",
            "\u001b[31mERROR: gym 0.17.2 has requirement cloudpickle<1.4.0,>=1.2.0, but you'll have cloudpickle 1.1.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cloudpickle, tensorflow-probability\n",
            "Successfully installed cloudpickle-1.1.1 tensorflow-probability-0.8.0rc0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cloudpickle"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEIk7FYD6lcF"
      },
      "source": [
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssOcn-nIOCcV"
      },
      "source": [
        "###Weather Model\n",
        "Taken direclty from the TensorFlow documentation (https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel).\n",
        "\n",
        "We will model a simple weather system and try to predict the temperature on each day given the following information.\n",
        "1. Cold days are encoded by a 0 and hot days are encoded by a 1.\n",
        "2. The first day in our sequence has an 80% chance of being cold.\n",
        "3. A cold day has a 30% chance of being followed by a hot day.\n",
        "4. A hot day has a 20% chance of being followed by a cold day.\n",
        "5. On each day the temperature is\n",
        " normally distributed with mean and standard deviation 0 and 5 on\n",
        " a cold day and mean and standard deviation 15 and 10 on a hot day.\n",
        "\n",
        "If you're unfamiliar with **standard deviation** it can be put simply as the range of expected values.\n",
        "\n",
        "In this example, on a hot day the average temperature is 15 and ranges from 5 to 25.\n",
        "\n",
        "To model this in TensorFlow we will do the following.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LBLEJp4YlIf"
      },
      "source": [
        "tfd = tfp.distributions  # making a shortcut for later on\n",
        "initial_distribution = tfd.Categorical(probs=[0.2, 0.8])  # Refer to point 2 above\n",
        "transition_distribution = tfd.Categorical(probs=[[0.5, 0.5],\n",
        "                                                 [0.2, 0.8]])  # refer to points 3 and 4 above\n",
        "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.])  # refer to point 5 above\n",
        "\n",
        "# the loc argument represents the mean and the scale is the standard devitation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XtTg0l04mqc"
      },
      "source": [
        "We've now created distribution variables to model our system and it's time to create the hidden markov model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4M6cZww4mZk"
      },
      "source": [
        "model = tfd.HiddenMarkovModel(\n",
        "    initial_distribution=initial_distribution,\n",
        "    transition_distribution=transition_distribution,\n",
        "    observation_distribution=observation_distribution,\n",
        "    num_steps=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ0XIA2M5gqD"
      },
      "source": [
        "The number of steps represents the number of days that we would like to predict information for. In this case we've chosen 7, an entire week.\n",
        "\n",
        "To get the **expected temperatures** on each day we can do the following."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plVVG4fi55Jv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cef2d0a3-0edf-4226-ad65-43245933109f"
      },
      "source": [
        "mean = model.mean()\n",
        "\n",
        "# due to the way TensorFlow works on a lower level we need to evaluate part of the graph\n",
        "# from within a session to see the value of this tensor\n",
        "\n",
        "# in the new version of tensorflow we need to use tf.compat.v1.Session() rather than just tf.Session()\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  print(mean.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12.       11.1      10.83     10.748999 10.724699 10.71741  10.715222]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEeIRxlbx0wY"
      },
      "source": [
        "##Sources\n",
        "\n",
        "1. Chen, James. “Line Of Best Fit.” Investopedia, Investopedia, 29 Jan. 2020, www.investopedia.com/terms/l/line-of-best-fit.asp.\n",
        "2. “Tf.feature_column.categorical_column_with_vocabulary_list.” TensorFlow, www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list?version=stable.\n",
        "3. “Build a Linear Model with Estimators &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/estimator/linear.\n",
        "4. Staff, EasyBib. “The Free Automatic Bibliography Composer.” EasyBib, Chegg, 1 Jan. 2020, www.easybib.com/project/style/mla8?id=1582473656_5e52a1b8c84d52.80301186.\n",
        "5. Seif, George. “The 5 Clustering Algorithms Data Scientists Need to Know.” Medium, Towards Data Science, 14 Sept. 2019, https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68.\n",
        "6. Definition of Hidden Markov Model, http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html.\n",
        "7. “Tfp.distributions.HiddenMarkovModel &nbsp;: &nbsp; TensorFlow Probability.” TensorFlow, www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqVqT_Cxh4Ho"
      },
      "source": [
        "#Introduction to Neural Networks\n",
        "In this notebook you will learn how to create and use a neural network to classify articles of clothing. To achieve this, we will use a sub module of TensorFlow called *keras*.\n",
        "\n",
        "*This guide is based on the following TensorFlow documentation.*\n",
        "\n",
        "https://www.tensorflow.org/tutorials/keras/classification\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFQqW9r-ikJb"
      },
      "source": [
        "##Keras\n",
        "Before we dive in and start discussing neural networks, I'd like to give a breif introduction to keras.\n",
        "\n",
        "From the keras official documentation (https://keras.io/) keras is described as follows.\n",
        "\n",
        "\"Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.\n",
        "\n",
        "Use Keras if you need a deep learning library that:\n",
        "\n",
        "- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
        "- Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
        "- Runs seamlessly on CPU and GPU.\"\n",
        "\n",
        "Keras is a very powerful module that allows us to avoid having to build neural networks from scratch. It also hides a lot of mathematical complexity (that otherwise we would have to implement) inside of helpful packages, modules and methods.\n",
        "\n",
        "In this guide we will use keras to quickly develop neural networks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hivk879ZQhxU"
      },
      "source": [
        "##What is a Neural Network\n",
        "A neural network model is a collection of layers.\n",
        "So, what are these magical things that have been beating chess grandmasters, driving cars, detecting cancer cells and winning video games?\n",
        "\n",
        "A deep neural network is a layered representation of data. The term \"deep\" refers to the presence of multiple layers. Recall that in our core learning algorithms (like linear regression) data was not transformed or modified within the model, it simply existed in one layer. We passed some features to our model, some math was done, an answer was returned. The data was not changed or transformed throughout this process. A neural network processes our data differently. It attempts to represent our data in different ways and in different dimensions by applying specific operations to transform our data at each layer. Another way to express this is that at each layer our data is transformed in order to learn more about it. By performing these transformations, the model can better understand our data and therefore provide a better prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOqUCZ2klTAq"
      },
      "source": [
        "##How it Works\n",
        "Before going into too much detail I will provide a very surface level explination of how neural networks work on a mathematical level. All the terms and concepts I discuss will be defined and explained in more detail below.\n",
        "\n",
        "On a lower level neural networks are simply a combination of elementry math operations and some more advanced linear algebra. Each neural network consists of a sequence of layers in which data passes through. These layers are made up on neurons and the neurons of one layer are connected to the next (see below). These connections are defined by what we call a weight (some numeric value). Each layer also has something called a bias, this is simply an extra neuron that has no connections and holds a single numeric value. Data starts at the input layer and is trasnformed as it passes through subsequent layers. The data at each subsequent neuron is defined as the following.\n",
        "\n",
        "> $Y =(\\sum_{i=0}^n w_i x_i) + b$\n",
        "\n",
        "> $w$ stands for the weight of each connection to the neuron\n",
        "\n",
        "> $x$ stands for the value of the connected neuron from the previous value\n",
        "\n",
        "> $b$ stands for the bias at each layer, this is a constant\n",
        "\n",
        "> $n$ is the number of connections\n",
        "\n",
        "> $Y$ is the output of the current neuron\n",
        "\n",
        "> $\\sum$ stands for sum\n",
        "\n",
        "The equation you just read is called a weighed sum. We will take this weighted sum at each and every neuron as we pass information through the network. Then we will add what's called a bias to this sum. The bias allows us to shift the network up or down by a constant value. It is like the y-intercept of a line.\n",
        "\n",
        "But that equation is the not complete one! We forgot a crucial part, **the activation function**. This is a function that we apply to the equation seen above to add complexity and dimensionality to our network. Our new equation with the addition of an activation function $F(x)$ is seen below.\n",
        "\n",
        "> $Y =F((\\sum_{i=0}^n w_i x_i) + b)$\n",
        "\n",
        "Our network will start with predefined activation functions (they may be different at each layer) but random weights and biases. As we train the network by feeding it data it will learn the correct weights and biases and adjust the network accordingly using a technqiue called **backpropagation** (explained below). Once the correct weights and biases have been learned our network will hopefully be able to give us meaningful predictions. We get these predictions by observing the values at our final layer, the output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-oMh18_j5kl"
      },
      "source": [
        "##Breaking Down The Neural Network!\n",
        "\n",
        "Before we dive into any code lets break down how a neural network works and what it does.\n",
        "\n",
        "![](http://www.extremetech.com/wp-content/uploads/2015/07/NeuralNetwork.png)\n",
        "*Figure 1*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9hd-R1ulSdp"
      },
      "source": [
        "###Data\n",
        "The type of data a neural network processes varies drastically based on the problem being solved. When we build a neural network, we define what shape and kind of data it can accept. It may sometimes be neccessary to modify our dataset so that it can be passed to our neural network.\n",
        "\n",
        "Some common types of data a neural network uses are listed below.\n",
        "- Vector Data (2D)\n",
        "- Timeseries or Sequence (3D)\n",
        "- Image Data (4D)\n",
        "- Video Data (5D)\n",
        "\n",
        "There are of course many different types or data, but these are the main categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyxxs7oMlWtz"
      },
      "source": [
        "###Layers\n",
        "As we mentioned earlier each neural network consists of multiple layers. At each layer a different transformation of data occurs. Our initial input data is fed through the layers and eventually arrives at the output layer where we will obtain the result.\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a 2D convolutional layer with TensorFlow\n",
        "conv_layer = tf.keras.layers.Conv2D()\n",
        "```\n",
        "\n",
        "####Input Layer\n",
        "The input layer is the layer that our initial data is passed to. It is the first layer in our neural network.\n",
        "####Output Layer\n",
        "The output layer is the layer that we will retrive our results from. Once the data has passed through all other layers it will arrive here.\n",
        "####Hidden Layer(s)\n",
        "All the other layers in our neural network are called \"hidden layers\". This is because they are hidden to us, we cannot observe them. Most neural networks consist of at least one hidden layer but can have an unlimited amount. Typically, the more complex the model the more hidden layers.\n",
        "\n",
        "The most straightforward way in TensorFlow to a neural network model us using the ```tf.keras.Sequential``` API, which allows you to stack layers in a way that the computation will be performed sequentially (one layer after the other):\n",
        "```\n",
        "# Create a basic neural network model with TensorFlow\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape),\n",
        "    # Add layers here\n",
        "\t\t# Computation will happen layer by layer sequentially\n",
        "])\n",
        "```\n",
        "\n",
        "\n",
        "####Neurons\n",
        "Each layer is made up of what are called neurons. Neurons have a few different properties that we will discuss later. The important aspect to understand now is that each neuron is responsible for generating/holding/passing ONE numeric value.\n",
        "\n",
        "This means that in the case of our input layer it will have as many neurons as we have input information. For example, say we want to pass an image that is 28x28 pixels, thats 784 pixels. We would need 784 neurons in our input layer to capture each of these pixels.\n",
        "\n",
        "This also means that our output layer will have as many neurons as we have output information. The output is a little more complicated to understand so I'll refrain from an example right now but hopefully you're getting the idea.\n",
        "\n",
        "But what about our hidden layers? Well these have as many neurons as we decide. We'll discuss how we can pick these values later but understand a hidden layer can have any number of neurons.\n",
        "####Connected Layers\n",
        "So how are all these layers connected? Well the neurons in one layer will be connected to neurons in the subsequent layer. However, the neurons can be connected in a variety of different ways.\n",
        "\n",
        "Take for example *Figure 1* (look above). Each neuron in one layer is connected to every neuron in the next layer. This is called a **dense** layer. There are many other ways of connecting layers but well discuss those as we see them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_bM6nQ-PZBY"
      },
      "source": [
        "###Weights\n",
        "Weights are associated with each connection in our neural network. Every pair of connected nodes will have one weight that denotes the strength of the connection between them. These are vital to the inner workings of a neural network and will be tweaked as the neural network is trained. The model will try to determine what these weights should be to achieve the best result. Weights start out at a constant or random value and will change as the network sees training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwYq9doXeIl-"
      },
      "source": [
        "###Biases\n",
        "Biases are another important part of neural networks and will also be tweaked as the model is trained. A bias is simply a constant value associated with each layer. It can be thought of as an extra neuron that has no connections. The purpose of a bias is to shift an entire activation function by a constant value. This allows a lot more flexibllity when it comes to choosing an activation and training the network. There is one bias for each layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F92rhvd6PcRI"
      },
      "source": [
        "###Activation Function\n",
        "Activation functions are simply a function that is applied to the weighed sum of a neuron. They can be anything we want but are typically higher order/degree functions that aim to add a higher dimension to our data. We would want to do this to introduce more comolexity to our model. By transforming our data to a higher dimension, we can typically make better, more complex predictions.\n",
        "\n",
        "A list of some common activation functions and their graphs can be seen below.\n",
        "\n",
        "- Relu (Rectified Linear Unit)\n",
        "\n",
        "![alt text](https://yashuseth.files.wordpress.com/2018/02/relu-function.png?w=309&h=274)\n",
        "- Tanh (Hyperbolic Tangent)\n",
        "\n",
        "![alt text](http://mathworld.wolfram.com/images/interactive/TanhReal.gif)\n",
        "- Sigmoid\n",
        "\n",
        "![alt text](https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2xNjpctlBUM"
      },
      "source": [
        "###Backpropagation\n",
        "Backpropagation is the fundemental algorithm behind training neural networks. It is what changes the weights and biases of our network. To fully explain this process, we need to start by discussing something called a cost/loss function.\n",
        "\n",
        "####Loss/Cost Function\n",
        "As we now know our neural network feeds information through the layers until it eventually reaches an output layer. This layer contains the results that we look at to determine the prediciton from our network. In the training phase it is likely that our network will make many mistakes and poor predicitions. In fact, at the start of training our network doesn't know anything (it has random weights and biases)!\n",
        "\n",
        "Loss functions are used to measure the difference between the predicted and true values in a machine learning problem.measures how wrong the model is (the higher the loss, the more wrong the model, so lower is better). Common loss values include ```tf.keras.losses.CategoricalCrossentropy``` for multi-class classification problems and ```tf.keras.losses.BinaryCrossentropy``` for binary classification problems.\n",
        "\n",
        "The higher the loss value, the more wrong the model.\n",
        "\n",
        "A model with a loss value of 0 is either:\n",
        "\n",
        "Broken (because there has been a data leak and the model has seen data it was supposed to test on).\n",
        "Perfect (it predicts the unseen data based on patterns its learn in the training data perfectly).\n",
        "\n",
        "We need some way of evaluating if the network is doing well and how well it is doing. For our training data we have the features (input) and the labels (expected output), because of this we can compare the output from our network to the expected output. Based on the difference between these values we can determine if our network has done a good job or poor job. If the network has done a good job, we'll make minor changes to the weights and biases. If it has done a poor job our changes may be more drastic.\n",
        "\n",
        "So, this is where the cost/loss function comes in. This function is responsible for determining how well the network did. We pass it the output and the expected output, and it returns to us some value representing the cost/loss of the network. This effectively makes the networks job to optimize this cost function, trying to make it as low as possible.\n",
        "\n",
        "Some common loss/cost functions include.\n",
        "- Mean Squared Error\n",
        "- Mean Absolute Error\n",
        "- Hinge Loss\n",
        "\n",
        "####Gradient Descent\n",
        "Gradient descent and backpropagation are closely related. Gradient descent is the algorithm used to find the optimal paramaters (weights and biases) for our network, while backpropagation is the process of calculating the gradient that is used in the gradient descent step.\n",
        "\n",
        "Gradient descent requires some pretty advanced calculus and linear algebra to understand so we'll stay away from that for now. Let's just read the formal definition for now.\n",
        "\n",
        "\"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.\" (https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html)\n",
        "\n",
        "And that's all we really need to know for now. I'll direct you to the video for a more in depth explination.\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1000/1*iU1QCnSTKrDjIPjSAENLuQ.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KiTMDCKlBI7"
      },
      "source": [
        "###Optimizer\n",
        "You may sometimes see the term optimizer or optimization function. This is simply the function that implements the backpropagation algorithm described above.\n",
        "Optimizers are used to update the model parameters during training, based on the gradients of the loss function.\n",
        "\n",
        "They are responsible for finding the optimal values of the model parameters that minimize the loss.\n",
        "\n",
        "Optimizer = tries to adjust the models parameters to lower the loss value. Common optimizers include ```tf.keras.optimizers.SGD``` (Stochastic Gradient Descent) and tf.keras.optimizers.Adam. Each optimizer comes with generally good default settings, however, of the most important values to set is the learning_rate hyperparameter.\n",
        "\n",
        "\n",
        "In essence, an optimizer will adjust the weights and bias values in a neural network’s layers to make sure the model’s patterns better match the input data.\n",
        "\n",
        "Here's a list of a few common ones.\n",
        "- Gradient Descent\n",
        "- Stochastic Gradient Descent\n",
        "- Mini-Batch Gradient Descent\n",
        "- Momentum\n",
        "- Nesterov Accelerated Gradient\n",
        "\n",
        "represented as ```tf.keras.optimizers``` objects, which can be customized or chosen from a wide range of built-in options.\n",
        "\n",
        "*This article explains them quite well is where I've pulled this list from.*\n",
        "\n",
        "(https://medium.com/@sdoshi579/optimizers-for-training-neural-network-59450d71caf6)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Callbacks\n",
        "Callbacks are functions that are executed at various stages of training, allowing you to customize and monitor the training process.\n",
        "\n",
        "They can be used to implement several helpful auxiliary functions to training such as:\n",
        "\n",
        "- Early stopping — stop a model from training if it hasn’t improved in a certain amount of steps.\n",
        "- Model checkpointing — save a model’s progress at specified points.\n",
        "- Learning rate scheduling — adjust a model’s learning rate (to better facilitate learning) at programmatic intervals.\n",
        "\n",
        "In TensorFlow, callbacks are represented as ```tf.keras.callbacks``` objects, which can be customized or chosen from a wide range of built-in options"
      ],
      "metadata": {
        "id": "vtx3BA2Ygv4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation\n",
        "Data augmentation is a technique used in computer vision to increase the size and diversity of the training dataset, by applying transformations to the data, such as rotations, flips, and color shifts.\n",
        "\n",
        "It can help to prevent overfitting (a model learning the patterns of the data too well) and improve the generalization of the model.\n",
        "\n",
        "In TensorFlow, data augmentation can be implemented using various layers from tf.keras.layers, which provides a wide range of image transformations, such as:\n",
        "\n",
        "```tf.keras.layers.Resizing``` — resize an image to a target size.\n",
        "\n",
        "```tf.keras.layers.Rescaling``` — rescale an image to a target scale.\n",
        "\n",
        "```tf.keras.layers.RandomFlip``` — randomly flip an image (horizontal or vertical)."
      ],
      "metadata": {
        "id": "PE0l4CBziAee"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc5hFCLSiDNr"
      },
      "source": [
        "##Creating a Neural Network\n",
        "Okay now you have reached the exciting part of this tutorial! No more math and complex explinations. Time to get hands on and train a very basic neural network.\n",
        "\n",
        "*As stated earlier this guide is based off of the following TensorFlow tutorial.*\n",
        "https://www.tensorflow.org/tutorials/keras/classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3io6gbUrjOQY"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8t_EdO8jEHz"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_iFN10li6V1"
      },
      "source": [
        "###Dataset\n",
        "For this tutorial we will use the MNIST Fashion Dataset. This is a dataset that is included in keras.\n",
        "\n",
        "This dataset includes 60,000 images for training and 10,000 images for validation/testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQmVmgOxjCOV"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist  # load dataset\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  # split into tetsing and training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcIall2njfn1"
      },
      "source": [
        "Let's have a look at this data to see what we are working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhLXRxOdjisI"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2npdFHwjsLS"
      },
      "source": [
        "So we've got 60,000 images that are made up of 28x28 pixels (784 in total)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m280zyPqj3ws"
      },
      "source": [
        "train_images[0,23,23]  # let's have a look at one pixel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUciblEwkBe4"
      },
      "source": [
        "Our pixel values are between 0 and 255, 0 being black and 255 being white. This means we have a grayscale image as there are no color channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn78KO7fkQPJ"
      },
      "source": [
        "train_labels[:10]  # let's have a look at the first 10 training labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r90qZKsnkaW7"
      },
      "source": [
        "Our labels are integers ranging from 0 - 9. Each integer represents a specific article of clothing. We'll create an array of label names to indicate which is which."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBiICD2tkne8"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rv06eD8krMR"
      },
      "source": [
        "Fianlly let's look at what some of these images look like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfc8LV4Pkq0X"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[1])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_DC1b0grL1N"
      },
      "source": [
        "##Data Preprocessing\n",
        "The last step before creating our model is to *preprocess* our data. This simply means applying some prior transformations to our data before feeding it the model. In this case we will simply scale all our greyscale pixel values (0-255) to be between 0 and 1. We can do this by dividing each value in the training and testing sets by 255.0. We do this because smaller values will make it easier for the model to process our values.\n",
        "\n",
        "Preprocessing layers include layers for:\n",
        "\n",
        "- Text preprocessing such as ```tf.keras.layers.TextVectorization``` (turns text into numbers).\n",
        "- Numerical features preprocessing such as ```tf.keras.layers.Normalization```.\n",
        "- Categorical features preprocessing such as ```tf.keras.layers```.CategoryEncoding.\n",
        "- Image preprocessing such as ```tf.keras.layers.Resizing``` to resize a batch of images to a target size.\n",
        "You can also use tf.keras.layers to perform image data augmentation during training:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHde8MYW0OQo"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHOX6GqR0QuD"
      },
      "source": [
        "##Building the Model\n",
        "Now it's time to build the model! We are going to use a keras *sequential* model with three different layers. This model represents a feed-forward neural network (one that passes values from left to right). We'll break down each layer and its architecture below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDxodHMv0xgG"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),  # input layer (1)\n",
        "    keras.layers.Dense(128, activation='relu'),  # hidden layer (2)\n",
        "    keras.layers.Dense(10, activation='softmax') # output layer (3)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-bL-I5w0414"
      },
      "source": [
        "**Layer 1:** This is our input layer and it will conist of 784 neurons. We use the flatten layer with an input shape of (28,28) to denote that our input should come in in that shape. The flatten means that our layer will reshape the shape (28,28) array into a vector of 784 neurons so that each pixel will be associated with one neuron.\n",
        "\n",
        "**Layer 2:** This is our first and only hidden layer. The *dense* denotes that this layer will be fully connected and each neuron from the previous layer connects to each neuron of this layer. It has 128 neurons and uses the rectify linear unit activation function.\n",
        "\n",
        "**Layer 3:** This is our output later and is also a dense layer. It has 10 neurons that we will look at to determine our models output. Each neuron represnts the probabillity of a given image being one of the 10 different classes. The activation function *softmax* is used on this layer to calculate a probabillity distribution for each class. This means the value of any neuron in this layer will be between 0 and 1, where 1 represents a high probabillity of the image being that class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j1UF9QH21Ex"
      },
      "source": [
        "###Compile the Model\n",
        "The last step in building the model is to define the loss function, optimizer and metrics we would like to track. I won't go into detail about why we chose each of these right now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msigq4Ja29QX"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YYW5V_53OXV"
      },
      "source": [
        "##Training the Model\n",
        "Now it's finally time to train the model. Since we've already done all the work on our data this step is as easy as calling a single method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmAtc4uI3_C7"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10)  # we pass the data, labels and epochs and watch the magic!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6SRtNcF4K1O"
      },
      "source": [
        "##Evaluating the Model\n",
        "Now it's time to test/evaluate the model. We can do this quite easily using another builtin method from keras.\n",
        "\n",
        "The *verbose* argument is defined from the keras documentation as:\n",
        "\"verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\"\n",
        "(https://keras.io/models/sequential/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqI0FEO54XN1"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb4_EtfK5DuW"
      },
      "source": [
        "You'll likely notice that the accuracy here is lower than when training the model. This difference is reffered to as **overfitting**.\n",
        "\n",
        "And now we have a trained model that's ready to use to predict some values!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv0XpgwJ7GlW"
      },
      "source": [
        "##Making Predictions\n",
        "To make predictions we simply need to pass an array of data in the form we've specified in the input layer to ```.predict()``` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMAkNWii7Ufj"
      },
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmRgxuEc7Xjc"
      },
      "source": [
        "This method returns to us an array of predictions for each image we passed it. Let's have a look at the predictions for image 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y2eQtCr7fnd"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiRNg9Yr7lCt"
      },
      "source": [
        "If we wan't to get the value with the highest score we can use a useful function from numpy called ```argmax()```. This simply returns the index of the maximium value from a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaagMfi671ci"
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWY4SKYm8h93"
      },
      "source": [
        "And we can check if this is correct by looking at the value of the cooresponding test label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVNepduo8nEy"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8I1EqJu8qRl"
      },
      "source": [
        "##Verifying Predictions\n",
        "I've written a small function here to help us verify predictions with some simple visuals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HJV4JF789aC"
      },
      "source": [
        "COLOR = 'white'\n",
        "plt.rcParams['text.color'] = COLOR\n",
        "plt.rcParams['axes.labelcolor'] = COLOR\n",
        "\n",
        "def predict(model, image, correct_label):\n",
        "  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "  prediction = model.predict(np.array([image]))\n",
        "  predicted_class = class_names[np.argmax(prediction)]\n",
        "\n",
        "  show_image(image, class_names[correct_label], predicted_class)\n",
        "\n",
        "\n",
        "def show_image(img, label, guess):\n",
        "  plt.figure()\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "  plt.title(\"Excpected: \" + label)\n",
        "  plt.xlabel(\"Guess: \" + guess)\n",
        "  plt.colorbar()\n",
        "  plt.grid(False)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def get_number():\n",
        "  while True:\n",
        "    num = input(\"Pick a number: \")\n",
        "    if num.isdigit():\n",
        "      num = int(num)\n",
        "      if 0 <= num <= 1000:\n",
        "        return int(num)\n",
        "    else:\n",
        "      print(\"Try again...\")\n",
        "\n",
        "num = get_number()\n",
        "image = test_images[num]\n",
        "label = test_labels[num]\n",
        "predict(model, image, label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transfer Learning\n",
        "\n",
        "###Load Image Pretrained Models with TensorFlow\n",
        "You can find many image-based pretrained models in the ```tf.keras.applications``` API.\n",
        "\n",
        "For example, to load a pre-trained TensorFlow model (e.g., MobileNetV2, a fast computer vision model which can run on mobile devices) without the top classification layer:"
      ],
      "metadata": {
        "id": "gl4INGxT3N97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = tf.keras.applications.MobileNetV2(\n",
        "\t\tinput_shape=input_shape, # define input shape of your data\n",
        "    include_top=False, # customize top layer to your own problem\n",
        "\t\tweights='imagenet') # model weights have been pretrained on ImageNet\n"
      ],
      "metadata": {
        "id": "ZwyRk_VR3eO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Text and Other Pretrained Models with TensorFlow Hub\n",
        "There are many more models across different domains that can be loaded from TensorFlow Hub or tfhub.dev.\n",
        "\n",
        "These include models for images, text, video, audio and more.\n",
        "\n",
        "You can also load the models via the TensorFlow Python API or JavaScript API.\n",
        "\n",
        "For example, the LEALLA (Lightweight language-agnostic sentence embedding model supporting 109 languages) is great for encoding text into numbers and then finding patterns in those numbers such as similarity matching (e.g. matching two pieces of text which are similar semantically rather than just string matching).\n",
        "\n",
        "You can load it with:"
      ],
      "metadata": {
        "id": "rIQG-sbU3jH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Several sizes of model are available\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/google/LEALLA/LEALLA-small/1\")\n",
        "# encoder = hub.KerasLayer(\"https://tfhub.dev/google/LEALLA/LEALLA-base/1\")\n",
        "# encoder = hub.KerasLayer(\"https://tfhub.dev/google/LEALLA/LEALLA-large/1\")\n",
        "\n",
        "# Works for different languages\n",
        "english_sentences = tf.constant([\"dog\", \"Puppies are nice.\", \"I enjoy taking long walks along the beach with my dog.\"])\n",
        "italian_sentences = tf.constant([\"cane\", \"I cuccioli sono carini.\", \"Mi piace fare lunghe passeggiate lungo la spiaggia con il mio cane.\"])\n",
        "japanese_sentences = tf.constant([\"犬\", \"子犬はいいです\", \"私は犬と一緒にビーチを散歩するのが好きです\"])\n",
        "\n",
        "# Turn target texts into numbers\n",
        "english_embeds = encoder(english_sentences)\n",
        "japanese_embeds = encoder(japanese_sentences)\n",
        "italian_embeds = encoder(italian_sentences)\n",
        "\n",
        "# English-Italian similarity (how similar are the texts)\n",
        "print(np.matmul(english_embeds, np.transpose(italian_embeds)))\n",
        "\n",
        "# English-Japanese similarity (how similar are the texts)\n",
        "print(np.matmul(english_embeds, np.transpose(japanese_embeds)))\n",
        "\n",
        "# Italian-Japanese similarity (how similar are the texts)\n",
        "print(np.matmul(italian_embeds, np.transpose(japanese_embeds)))\n"
      ],
      "metadata": {
        "id": "EdoWvjzO3ucK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Freeze Pretrained Model Layers\n",
        "To preserve the patterns and weights learned by a pretrained model (to reuse them for your own problem), you can freeze them to stop them being updated during training:\n",
        "\n"
      ],
      "metadata": {
        "id": "liI4h2YY3zwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set layers in the pretrained_model to not update during training\n",
        "pretrained_model.trainable = False"
      ],
      "metadata": {
        "id": "lhmIDjD435GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Custom Layers and Train\n",
        "With a frozen pretrained model, you can add your own custom layers on top:"
      ],
      "metadata": {
        "id": "9ffjlNgJ391-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    pretrained_model, # frozen base model\n",
        "\n",
        "\t\t# Custom top layers take outputs from pretrained model and tailor to your\n",
        "\t\t# own problem\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(...)\n",
        "model.fit(...)"
      ],
      "metadata": {
        "id": "8v9SgS7ofWj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Layers with TensorFlow\n",
        "TensorFlow has plenty of in-built layers available via tf.keras.layers.\n",
        "\n",
        "These will get you through 95% of your model creation.\n",
        "\n",
        "However, sometimes you may want to create your own custom layer.\n",
        "\n",
        "To do so, you can subclass the tf.keras.layers.Layer class (the class from which all other layers are built on) and implement:\n",
        "\n",
        "__init__ — create all objects which are required for the layer (these are generally input-independent).\n",
        "A build() method — setup all input-dependent variables for the layer.\n",
        "A call() method — setup all steps in the forward computation (when you call the layer, what should it do to the inputs?).\n",
        "For example, let’s create a layer which just adds 1 to all variables on the input:"
      ],
      "metadata": {
        "id": "VFwodGUDh_f-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create all zeros tensor as input\n",
        "x = tf.zeros(10)\n",
        "\n",
        "# Create a layer which just adds 1 to all inputs\n",
        "class MyCustomLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(MyCustomLayer, self).__init__()\n",
        "        # Initialize layer attributes\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create layer weights (our layer doesn't use these)\n",
        "        self.kernel = self.add_weight(\"kernel\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define the forward pass (what happens when you call the layer?)\n",
        "        return inputs + 1 # add 1 to all inputs\n",
        "\n",
        "# Create and use the layer\n",
        "custom_layer = MyCustomLayer()\n",
        "custom_layer(x)\n",
        "\n",
        ">>> <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>\n"
      ],
      "metadata": {
        "id": "TeTW629Ih-9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom models via Model Subclassing\n",
        "Once you’ve created custom layers, you can stack them together using the Sequential API or the Functional API.\n",
        "\n",
        "However, you may also want to combine them via your own custom model class.\n",
        "\n",
        "You create your own custom model by subclassing tf.keras.Model.\n",
        "\n",
        "A tf.keras.Model is just like a tf.keras.layers.Layer but with added functionality such as the fit(), evaluate() and save() methods.\n",
        "\n",
        "Just like when creating a layer, you must define the call() method which defines the computation that happens when you call fit() on the model:\n"
      ],
      "metadata": {
        "id": "UR9t-E2_iToq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom model\n",
        "class MyCustomModel(tf.keras.Model):\n",
        "    def __init__(self, ...):\n",
        "        super(MyCustomModel, self).__init__()\n",
        "        # Initialize and create layers\n",
        "\n",
        "\t\t# call() defines what happens when you call fit() on the model\n",
        "    def call(self, inputs, training=False):\n",
        "        # Define the forward pass\n",
        "        return ...\n",
        "\n",
        "# Use your custom model\n",
        "custom_model = MyCustomModel(...)\n"
      ],
      "metadata": {
        "id": "hhCTJHhCicWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Loss Functions\n",
        "The loss function measures how wrong a model’s predictions are.\n",
        "\n",
        "The more wrong a model is, the higher the loss value will be.\n",
        "\n",
        "TensorFlow has many in-built loss functions available in the tf.keras.losses API.\n",
        "\n",
        "But if you’d like to create your own loss function, you can do so by subclassing tf.keras.losses.Loss (this is what all existing loss functions already do).\n",
        "\n",
        "For example, if we wanted to recreate mean absolute error (MAE), we could do so with:"
      ],
      "metadata": {
        "id": "HwFggxfy4G3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create y_true and y_pred values\n",
        "y_true = tf.ones(10)\n",
        "y_pred = y_true * 2\n",
        "\n",
        "# Create custom loss (recreate MAE)\n",
        "class MeanAbsoluteError(tf.keras.losses.Loss):\n",
        "  def call(self, y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.abs(y_pred - y_true))\n",
        "\n",
        "# Instantiate and use the custom loss value\n",
        "mae_loss = MeanAbsoluteError()\n",
        "mae_loss(y_true, y_pred)\n",
        "\n",
        ">>> <tf.Tensor: shape=(), dtype=float32, numpy=1.0>\n",
        "\n",
        "# Compile the model with the custom loss\n",
        "model.compile(optimizer=optimizer,\n",
        "\t\t\t\t\t\t  loss=mae_loss,\n",
        "\t\t\t\t\t\t\tmetrics=metrics)"
      ],
      "metadata": {
        "id": "EbD_-ocl4QTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Custom Metrics\n",
        "A metric is a human-readable value to measure how right your model is performing.\n",
        "\n",
        "For example, if a model achieved 99/100 correct predictions, you might say it had an accuracy of 99% (where accuracy is the metric of choice).\n",
        "\n",
        "TensorFlow has a bunch of pre-built metrics for all kinds of different problems available in ```tf.keras.metrics```.\n",
        "\n",
        "However, if you’d like to create your own custom metric, you can do so via subclassing ```tf.keras.metrics.Metric``` (the class all other existing TensorFlow metrics build on):"
      ],
      "metadata": {
        "id": "I3wpdSLw4YvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your own custom metric\n",
        "class MyCustomMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, ...):\n",
        "        super(MyCustomMetric, self).__init__()\n",
        "        # Initialize metric attributes\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Update the metric's state based on y_true and y_pred\n",
        "\n",
        "    def result(self):\n",
        "        # Compute and return the final result\n",
        "\n",
        "    def reset_states(self):\n",
        "        # Reset the metric's state\n",
        "\n",
        "# Use your own custom metric\n",
        "custom_metric = MyCustomMetric(...)"
      ],
      "metadata": {
        "id": "P-gyD5bv44ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization\n",
        "Because neural network models have incredible potential to learn patterns in data, they are prone to overfitting.\n",
        "\n",
        "Overfitting is when a model learns patterns in a training dataset too well.\n",
        "\n",
        "By too well, I mean it basically memorizes the patterns in the training set and doesn’t generalize to unseen data such as the test dataset.\n",
        "\n",
        "Such as when a student learns the course materials (training data) very well but fails the final exam (testing data).\n",
        "\n",
        "There are several techniques to prevent overfitting and these techniques are collectively known as regularization:\n",
        "\n",
        "- Get more training data (more data means more opportunities for a model to learn diverse patterns).\n",
        "- Add dropout (randomly remove connections in the network).\n",
        "- Add weight decay or weight regularization (make sure the weights don’t get too close to the target data).\n",
        "- Use data augmentation.\n",
        "- Use batch normalization or layer normalization.\n"
      ],
      "metadata": {
        "id": "SFkglJ3G5Uob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight decay/regularization\n",
        "You can add weight decay/regularization to a particular layer using L1 or L2 regularization via the tf.keras.regularizers API (see the TensorFlow documentation for more on each of these), let’s try L2 regularization:"
      ],
      "metadata": {
        "id": "1zh42FnX5iip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the regularizer\n",
        "l2_regularizer = tf.keras.regularizers.l2(l2=0.01)\n",
        "\n",
        "# Add it to the layer\n",
        "layer = tf.keras.layers.Dense(units,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Note: kernel is another word for \"weight matrix\"\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t    kernel_regularizer=l2_regularizer)"
      ],
      "metadata": {
        "id": "uSLUlfu35knS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout\n",
        "Dropout is another common regularization technique which randomly sets a specified fraction of input values to zero.\n",
        "\n",
        "The thought process here is that if a certain number (usually around 10-20%) of layer weights are set to zero, the remaining weights should be forced to be better representations of the data.\n",
        "\n",
        "Dropout is usually placed after and in between layers and can be created via ```tf.keras.layers.Dropout```."
      ],
      "metadata": {
        "id": "E4OqDDp05vKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dropout layer with a dropout rate of 10%\n",
        "dropout_layer = tf.keras.layers.Dropout(rate=0.1)"
      ],
      "metadata": {
        "id": "cEdVFDQd52OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning in TensorFlow\n",
        "Values that you can set yourself, such as the learning rate or number of units in a layer, of a machine learning model are known as hyperparameters.\n",
        "\n",
        "While there are often good defaults for these values, knowing the absolute best values is impossible ahead of time.\n",
        "\n",
        "The practice of finding the best values for these is known as hyperparameter tuning.\n",
        "\n",
        "You can either run multiple experiments adjusting the values by hand.\n",
        "\n",
        "Or you can write code to do it for you.\n",
        "\n",
        "The Keras Tuner library allows you to programmtically tune the hyperparameters of your TensorFlow and Keras models.\n",
        "\n",
        "The Keras Tuner library has four tuners available:\n",
        "\n",
        "- RandomSearch\n",
        "- Hyperband\n",
        "- BayesianOptimization\n",
        "- Sklearn\n",
        "The documentation explains each of these in more detail, however, here is an example of using RandomSearch to tune the hidden units in the first layer and the learning rate of the optimizer:\n",
        "\n"
      ],
      "metadata": {
        "id": "hsxgi6J358Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "\n",
        "import tensorflow as tf\n",
        "imporkeras_tuner import RandomSearch\n",
        "\n",
        "# Create dataset\n",
        "(img_train, label_train), (img_test, label_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize dataset\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0\n",
        "\n",
        "# Define a model to tune the hyperparameters of\n",
        "def build_model(hp):\n",
        "    # Tune the values of the first dense layer between\n",
        "    # 32 and 512\n",
        "    units_choice = hp.Int('units',\n",
        "                          min_value=32,\n",
        "                          max_value=512,\n",
        "                          step=32)\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)), # flatten the inputs\n",
        "        tf.keras.layers.Dense(units=units_choice, # these will be tuned\n",
        "                              activation='relu'),\n",
        "        tf.keras.layers.Dense(10,\n",
        "                              activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Tune the learning rate to be one of:\n",
        "    # 0.01, 0.001 or 0.0001\n",
        "    learning_rate_choices = hp.Choice('learning_rate',\n",
        "                                      values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_choices),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the tuner with RandomSearch\n",
        "tuner = RandomSearch(build_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_trials=5)\n",
        "\n",
        "# Run the hyperparameter search\n",
        "tuner.search(x=img_train,\n",
        "             y=label_train,\n",
        "             epochs=10,\n",
        "             validation_data=(img_test,\n",
        "                              label_test))\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "ypZpOpF46K3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mixed Precision Training in TensorFlow\n",
        "The default datatype for computing in TensorFlow is float32.\n",
        "\n",
        "However, lower-precision datatypes such as float16 can be used to speed up training (less precision means less numbers to compute on) without a significant loss to performance.\n",
        "\n",
        "If your GPU has a compute capability score of 7.0 or higher, it can benefit from using mixed precision training.\n",
        "\n",
        "TensorFlow enables automatic mixed precision training (e.g. it will allocate the float16 datatype to layers which are compatible with using it and will default to float32 when necessary) via the tensorflow.keras.mixed_precision API"
      ],
      "metadata": {
        "id": "8qaxdMoV6VyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Set the global policy to use mixed precision where possible\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Note: when using mixed precision training, ensure the last\n",
        "# layer has float32 output (for numerical stability)\n",
        "model.add(tf.keras.layers.Activation('softmax', dtype='float32'))\n",
        "\n",
        "# Train the model as usual and mixed precision will be applied where possible\n"
      ],
      "metadata": {
        "id": "tPxRYfiF6a-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Accumulation in TensorFlow\n",
        "Gradient accumulation can help when training on large batches that do not fit in memory.\n",
        "\n",
        "For example, let’s say you have a large neural network which performs well but runs into memory issues when using a batch size of 32 (larger batch sizes generally enables better learning opportunities).\n",
        "\n",
        "With gradient accumulation, you can simulate a larger batch size.\n",
        "\n",
        "For example, you could run with a batch size of 32 but only update the gradients (perform the large computation) every 4 steps.\n",
        "\n",
        "This effectively means you’re using a batch size of 8 (32/4) but getting the benefits of using a batch size of 32.\n",
        "\n",
        "This code example shows how the forward pass, loss calculation and gradient calculation happens on the whole batch but the gradient updates only happen once every 4 steps:"
      ],
      "metadata": {
        "id": "EV-Nc8Dz6g4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the optimizer and loss function as normal\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# Accumulate gradients and only update them every 4 steps\n",
        "accumulation_steps = 4\n",
        "\n",
        "# Create a tensor of zeros to store accumulated gradients\n",
        "accumulated_gradients = [tf.zeros_like(var) for var in model.trainable_variables]\n",
        "\n",
        "# Perform training loop\n",
        "for epoch in range(epochs):\n",
        "    for x_batch, y_batch in train_data:\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass gets performed on the whole batch\n",
        "            y_pred = model(x_batch, training=True)\n",
        "            # Compute loss on the whole batch\n",
        "            loss = loss_function(y_batch, y_pred)\n",
        "\n",
        "        # Compute gradients on whole batch\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        accumulated_gradients = [acc_grad + grad for acc_grad, grad in zip(accumulated_gradients, gradients)]\n",
        "\n",
        "\t\t\t\t# Only *update* gradients if step threshold is True\n",
        "        if step % accumulation_steps == 0:\n",
        "\t\t\t\t\t\t# Divide accumulated_gradients by number of steps\n",
        "\t\t\t\t\t\taccumulated_gradients = accumulated_graidents / accumulation_steps\n",
        "\n",
        "            # Apply accumulated gradients\n",
        "            optimizer.apply_gradients(zip(accumulated_gradients, model.trainable_variables))\n",
        "            # Reset accumulated gradients\n",
        "            accumulated_gradients = [tf.zeros_like(var) for var in model.trainable_variables]\n"
      ],
      "metadata": {
        "id": "xTxkE_9s6o1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Track in-depth model performance with TensorFlow Profiler\n",
        "The TensorFlow Profiler helps to track the performance of TensorFlow models down to finest the detail.\n",
        "\n",
        "It helps you understand what operations (ops) are consuming what hardware resources (time and memory wise) and thus allows you to modify various parts which may be taking more time than necessary.\n",
        "\n",
        "You can get started with the TensorFlow Profiler in several ways via the various profiling APIs:\n",
        "\n",
        "Via the TensorBoard Keras Callback, tf.keras.callbacks.TensorBoard (shown below)\n",
        "Via the ```tf.profiler``` Function API\n",
        "Via the ```tf.profiler.experimental.Profile()``` context manager\n",
        "The following is an example of using the TensorFlow Profiler with the TensorBoard Callback:"
      ],
      "metadata": {
        "id": "dO6nM11W6uzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorboard_plugin_profile\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Set up the log directory\n",
        "log_dir = \"logs\"\n",
        "\n",
        "# Enable the profiler in TensorBoard via callback\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # Select which batches to profile\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t profile_batch=(10, 20))\n",
        "\n",
        "# Train the model with the TensorBoard callback\n",
        "model.fit(x=x_train,\n",
        "\t\t\t\t\ty=y_train,\n",
        "\t\t\t\t\tepochs=10,\n",
        "\t\t\t\t\tbatch_size=32,\n",
        "\t\t\t\t\tvalidation_data=(x_val, y_val),\n",
        "\t\t\t\t\tcallbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "id": "pdg1AiFx68k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Distributed Training with TensorFlow\n",
        "Distributed training involves training TensorFlow models across multiple GPUs, machines or TPUs.\n",
        "\n",
        "This means you can take your existing code and run it at a larger scale and in turn create larger models and train on larger datasets.\n",
        "\n",
        "TensorFlow allows for distributed training to take place via the tf.distribute.Strategy API.\n",
        "\n",
        "There are several types of training strategy to use:\n",
        "\n",
        "- Single machine, single GPU — this is the default strategy and does not require tf.distribute.Strategy.\n",
        "- MirroredStrategy (tf.distribute.MirroredStrategy) — this mode supports synchronous distributed training on multiple GPUs on a single machine. Each variable is replicated across each GPU.\n",
        "- TPUStrategy (tf.distribute.TPUStrategy) — this mode allows the running of TensorFlow code on Tensor Processing Units (TPUs). TPUs are Google’s custom chips designed for machine learning workflows.\n",
        "- MultiWorkerMirroredStrategy (tf.distribute.MultiWorkerMirroredStrategy) — this mode allows for use of multiple machines with multiple GPUs (e.g. a cluster of 10 machines each with 8 GPUs).\n",
        "See more in the TensorFlow distributed training documentation.\n",
        "Let’s see an example of two distributed training options."
      ],
      "metadata": {
        "id": "POIvjaGj7MBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MirroredStrategy (one machine with multiple GPUs)\n",
        "```tf.distribute.MirroredStrategy``` is a synchronous training strategy that replicates the model and its variables across multiple GPUs on a single machine, for example, you may have 4 GPUs on a single machine:\n",
        "\n"
      ],
      "metadata": {
        "id": "mjad-uOk7ZHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Setup the training strategy\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Compile the model within the strategy context manager\n",
        "with mirrored_strategy.scope():\n",
        "    # Build and compile your model within the strategy scope\n",
        "    model = create_model()\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "# Train the model as usual\n",
        "model.fit(x_train, y_train, epochs, batch_size, validation_data=(x_val, y_val))\n"
      ],
      "metadata": {
        "id": "6-mf4cDL7hZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MultiWorkerMirroredStrategy (multiple machines, multiple GPUs)\n",
        "tf.distributed.MultiWorkerMirroredStrategy extends MirroredStrategy for synchronous training across multiple machines, each with multiple GPUs:"
      ],
      "metadata": {
        "id": "ZYW0uaEB7l2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Setup the training strategy\n",
        "multi_worker_mirrored_strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "# Compile the model within the strategy context manager\n",
        "with multi_worker_mirrored_strategy.scope():\n",
        "    # Build and compile your model within the strategy scope\n",
        "    model = create_model()\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "# Train the model as usual\n",
        "model.fit(x_train, y_train, epochs, batch_size, validation_data=(x_val, y_val))\n"
      ],
      "metadata": {
        "id": "zuet5GPx7u4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmbcLZZ0lo_2"
      },
      "source": [
        "##Sources\n",
        "\n",
        "1. Doshi, Sanket. “Various Optimization Algorithms For Training Neural Network.” Medium, Medium, 10 Mar. 2019, www.medium.com/@sdoshi579/optimizers-for-training-neural-network-59450d71caf6.\n",
        "\n",
        "2. “Basic Classification: Classify Images of Clothing &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/keras/classification.\n",
        "\n",
        "3. “Gradient Descent¶.” Gradient Descent - ML Glossary Documentation, www.ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html.\n",
        "\n",
        "4. Chollet François. Deep Learning with Python. Manning Publications Co., 2018.\n",
        "\n",
        "5. “Keras: The Python Deep Learning Library.” Home - Keras Documentation, www.keras.io/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_o2L3Io9t4c"
      },
      "source": [
        "#Deep Computer Vision\n",
        "\n",
        "In this guide we will learn how to peform *image classification and object detection/recognition* using deep computer vision with something called a **convolutional neural network**.\n",
        "\n",
        "The goal of our convolutional neural networks will be to classify and detect images or specific objects from within the image. We will be using image data as our features and a label for those images as our label or output.\n",
        "\n",
        "We already know how neural networks work so we can skip through the basics and move right into explaining the following concepts.\n",
        "- Image Data\n",
        "- Convolutional Layer\n",
        "- Pooling Layer\n",
        "- CNN Architectures\n",
        "\n",
        "The major differences we are about to see in these types of neural networks are the layers that make them up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdqlqfhLCHZl"
      },
      "source": [
        "##Image Data\n",
        "So far, we have dealt with pretty straight forward data that has 1 or 2 dimensions. Now we are about to deal with image data that is usually made up of 3 dimensions. These 3 dimensions are as follows:\n",
        "- image height\n",
        "- image width\n",
        "- color channels\n",
        "\n",
        "The only item in the list above you may not understand is **color channels**. The number of color channels represents the depth of an image and coorelates to the colors used in it. For example, an image with three channels is likely made up of rgb (red, green, blue) pixels. So, for each pixel we have three numeric values in the range 0-255 that define its color. For an image of color depth 1 we would likely have a greyscale image with one value defining each pixel, again in the range of 0-255.\n",
        "\n",
        "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure1.png)\n",
        "\n",
        "Keep this in mind as we discuss how our network works and the input/output of each layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mqznmTh--v2"
      },
      "source": [
        "##Convolutional Neural Network\n",
        "**Note:** I will use the term *convnet* and convolutional neural network interchangably.\n",
        "\n",
        "Each convolutional neural network is made up of one or many convolutional layers. These layers are different than the *dense* layers we have seen previously. Their goal is to find patterns from within images that can be used to classify the image or parts of it. But this may sound familiar to what our densly connected neural network in the previous section was doing, well that's becasue it is.\n",
        "\n",
        "The fundemental difference between a dense layer and a convolutional layer is that dense layers detect patterns globally while convolutional layers detect patterns locally. When we have a densly connected layer each node in that layer sees all the data from the previous layer. This means that this layer is looking at all the information and is only capable of analyzing the data in a global capacity. Our convolutional layer however will not be densly connected, this means it can detect local patterns using part of the input data to that layer.\n",
        "\n",
        "*Let's have a look at how a densly connected layer would look at an image vs how a convolutional layer would.*\n",
        "\n",
        "This is our image; the goal of our network will be to determine whether this image is a cat or not.\n",
        "![alt text](https://img.webmd.com/dtmcms/live/webmd/consumer_assets/site_images/article_thumbnails/reference_guide/cat_weight_ref_guide/1800x1200_cat_weight_ref_guide.jpg)\n",
        "\n",
        "**Dense Layer:** A dense layer will consider the ENTIRE image. It will look at all the pixels and use that information to generate some output.\n",
        "\n",
        "**Convolutional Layer:** The convolutional layer will look at specific parts of the image. In this example let's say it analyzes the highlighted parts below and detects patterns there.\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1M7v7S-b-zisFLI_G4ZY_RdUJQrGpJ3zt)\n",
        "\n",
        "Can you see why this might make these networks more useful?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIQvxFu_FB3h"
      },
      "source": [
        "###How They Work\n",
        "A dense neural network learns patterns that are present in one specific area of an image. This means if a pattern that the network knows is present in a different area of the image it will have to learn the pattern again in that new area to be able to detect it.\n",
        "\n",
        "*Let's use an example to better illustrate this.*\n",
        "\n",
        "We'll consider that we have a dense neural network that has learned what an eye looks like from a sample of dog images.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=16FJKkVS_lZToQOCOOy6ohUpspWgtoQ-c)\n",
        "\n",
        "Let's say it's determined that an image is likely to be a dog if an eye is present in the boxed off locations of the image above.\n",
        "\n",
        "Now let's flip the image.\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1V7Dh7BiaOvMq5Pm_jzpQfJTZcpPNmN0W)\n",
        "\n",
        "Since our densly connected network has only recognized patterns globally it will look where it thinks the eyes should be present. Clearly it does not find them there and therefore would likely determine this image is not a dog. Even though the pattern of the eyes is present, it's just in a different location.\n",
        "\n",
        "Since convolutional layers learn and detect patterns from different areas of the image, they don't have problems with the example we just illustrated. They know what an eye looks like and by analyzing different parts of the image can find where it is present.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20J29gz-NroA"
      },
      "source": [
        "###Multiple Convolutional Layers\n",
        "In our models it is quite common to have more than one convolutional layer. Even the basic example we will use in this guide will be made up of 3 convolutional layers. These layers work together by increasing complexity and abstraction at each subsequent layer. The first layer might be responsible for picking up edges and short lines, while the second layer will take as input these lines and start forming shapes or polygons. Finally, the last layer might take these shapes and determine which combiantions make up a specific image.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii-a9rXzRwNi"
      },
      "source": [
        "##Feature Maps\n",
        "You may see me use the term *feature map* throughout this tutorial. This term simply stands for a 3D tensor with two spacial axes (width and height) and one depth axis. Our convolutional layers take feature maps as their input and return a new feature map that reprsents the prescence of spcific filters from the previous feature map. These are what we call *response maps*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OScABB-ScXHx"
      },
      "source": [
        "##Layer Parameters\n",
        "A convolutional layer is defined by two key parameters.\n",
        "\n",
        "####**Filters**\n",
        "A filter is a m x n pattern of pixels that we are looking for in an image. The number of filters in a convolutional layer reprsents how many patterns each layer is looking for and what the depth of our response map will be. If we are looking for 32 different patterns/filters than our output feature map (aka the response map) will have a depth of 32. Each one of the 32 layers of depth will be a matrix of some size containing values indicating if the filter was present at that location or not.\n",
        "\n",
        "Here's a great illustration from the book \"Deep Learning with Python\" by Francois Chollet (pg 124).\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1HcLvvLKvLCCGuGZPMvKYz437FbbCC2eB)\n",
        "\n",
        "####**Sample Size**\n",
        "This isn't really the best term to describe this, but each convolutional layer is going to examine n x m blocks of pixels in each image. Typically, we'll consider 3x3 or 5x5 blocks. In the example above we use a 3x3 \"sample size\". This size will be the same as the size of our filter.\n",
        "\n",
        "Our layers work by sliding these filters of n x m pixels over every possible position in our image and populating a new feature map/response map indicating whether the filter is present at each location.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnzqr8Dzjchd"
      },
      "source": [
        "##Borders and Padding\n",
        "The more mathematical of you may have realized that if we slide a filter of let's say size 3x3 over our image well consider less positions for our filter than pixels in our input. Look at the example below.\n",
        "\n",
        "*Image from \"Deep Learning with Python\" by Francois Chollet (pg 126).*\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1OEfXrV16NBjwAafgBfYYcWOyBCHqaZ5M)\n",
        "\n",
        "This means our response map will have a slightly smaller width and height than our original image. This is fine but sometimes we want our response map to have the same dimensions. We can accomplish this by using something called *padding*.\n",
        "\n",
        "**Padding** is simply the addition of the appropriate number of rows and/or columns to your input data such that each pixel can be centered by the filter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDwH2eOMmt_N"
      },
      "source": [
        "##Strides\n",
        "In the previous sections we assumed that the filters would be slid continously through the image such that it covered every possible position. This is common but sometimes we introduce the idea of a **stride** to our convolutional layer. The stride size reprsents how many rows/cols we will move the filter each time. These are not used very frequently so we'll move on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCsVC-4UnfC8"
      },
      "source": [
        "##Pooling\n",
        "You may recall that our convnets are made up of a stack of convolution and pooling layers.\n",
        "\n",
        "The idea behind a pooling layer is to downsample our feature maps and reduce their dimensions. They work in a similar way to convolutional layers where they extract windows from the feature map and return a response map of the max, min or average values of each channel. Pooling is usually done using windows of size 2x2 and a stride of 2. This will reduce the size of the feature map by a factor of two and return a response map that is 2x smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqLsm2XzNQSE"
      },
      "source": [
        "##Creating a Convnet\n",
        "\n",
        "Now it is time to create our first convnet! This example is for the purpose of getting familiar with CNN architectures, we will talk about how to improves its performance later.\n",
        "\n",
        "*This tutorial is based on the following guide from the TensorFlow documentation: https://www.tensorflow.org/tutorials/images/cnn*\n",
        "\n",
        "###Dataset\n",
        "The problem we will consider here is classifying 10 different everyday objects. The dataset we will use is built into tensorflow and called the [**CIFAR Image Dataset.**](https://www.cs.toronto.edu/~kriz/cifar.html) It contains 60,000 32x32 color images with 6000 images of each class.\n",
        "\n",
        "The labels in this dataset are the following:\n",
        "- Airplane\n",
        "- Automobile\n",
        "- Bird\n",
        "- Cat\n",
        "- Deer\n",
        "- Dog\n",
        "- Frog\n",
        "- Horse\n",
        "- Ship\n",
        "- Truck\n",
        "\n",
        "We'll load the dataset and have a look at some of the images below.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnIbwiK7Ohv2"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49wbEaM1PCCR"
      },
      "source": [
        "#  LOAD AND SPLIT DATASET\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp0yAAcuPHFN"
      },
      "source": [
        "# Let's look at a one image\n",
        "IMG_INDEX = 7  # change this to look at other images\n",
        "\n",
        "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPqeddhcPwpc"
      },
      "source": [
        "##CNN Architecture\n",
        "A common architecture for a CNN is a stack of Conv2D and MaxPooling2D layers followed by a few denesly connected layers. To idea is that the stack of convolutional and maxPooling layers extract the features from the image. Then these features are flattened and fed to densly connected layers that determine the class of an image based on the presence of features.\n",
        "\n",
        "We will start by building the **Convolutional Base**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibuJZqAXQrWJ"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tybTBoi_Qtxl"
      },
      "source": [
        "**Layer 1**\n",
        "\n",
        "The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.\n",
        "\n",
        "**Layer 2**\n",
        "\n",
        "This layer will perform the max pooling operation using 2x2 samples and a stride of 2.\n",
        "\n",
        "**Other Layers**\n",
        "\n",
        "The next set of layers do very similar things but take as input the feature map from the previous layer. They also increase the frequency of filters from 32 to 64. We can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford (computationally) to add more depth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QahwuduSEDG"
      },
      "source": [
        "model.summary()  # let's have a look at our model so far"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjtADcfmSI9q"
      },
      "source": [
        "##Adding Dense Layers\n",
        "So far, we have just completed the **convolutional base**. Now we need to take these extracted features and add a way to classify them. This is why we add the following layers to our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9TMZH_oSULo"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEzHX-7ESeCl"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdPxFvHdTLRK"
      },
      "source": [
        "##Training\n",
        "Now we will train and compile the model using the recommended hyper paramaters from tensorflow.\n",
        "\n",
        "*Note: This will take much longer than previous models!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5loIug93TW1E"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=4,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkdRKQnETgLv"
      },
      "source": [
        "##Evaluating the Model\n",
        "We can determine how well the model performed by looking at it's performance on the test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I2vJFiiTkQE"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cstpZFVaY7YH"
      },
      "source": [
        "##Working with Small Datasets\n",
        "In the situation where you don't have millions of images it is difficult to train a CNN from scratch that performs very well. This is why we will learn about a few techniques we can use to train CNN's on small datasets of just a few thousand images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D4iWJ17ZRt_"
      },
      "source": [
        "###Data Augmentation\n",
        "To avoid overfitting and create a larger dataset from a smaller one we can use a technique called data augmentation. This is simply performing random transofrmations on our images so that our model can generalize better. These transformations can be things like compressions, rotations, stretches and even color changes.\n",
        "\n",
        "Fortunately, keras can help us do this. Look at the code below to an example of data augmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sOet0hQZ-gR"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# creates a data generator object that transforms images\n",
        "datagen = ImageDataGenerator(\n",
        "rotation_range=40,\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True,\n",
        "fill_mode='nearest')\n",
        "\n",
        "# pick an image to transform\n",
        "test_img = train_images[20]\n",
        "img = image.img_to_array(test_img)  # convert image to numpy arry\n",
        "img = img.reshape((1,) + img.shape)  # reshape image\n",
        "\n",
        "i = 0\n",
        "\n",
        "for batch in datagen.flow(img, save_prefix='test', save_format='jpeg'):  # this loops runs forever until we break, saving images to current directory with specified prefix\n",
        "    plt.figure(i)\n",
        "    plot = plt.imshow(image.img_to_array(batch[0]))\n",
        "    i += 1\n",
        "    if i > 4:  # show 4 images\n",
        "        break\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc9RyHPYUnSK"
      },
      "source": [
        "###Pretrained Models\n",
        "You would have noticed that the model above takes a few minutes to train in the NoteBook and only gives an accuaracy of ~70%. This is okay but surely there is a way to improve on this.\n",
        "\n",
        "In this section we will talk about using a pretrained CNN as apart of our own custom network to improve the accuracy of our model. We know that CNN's alone (with no dense layers) don't do anything other than map the presence of features from our input. This means we can use a pretrained CNN, one trained on millions of images, as the start of our model. This will allow us to have a very good convolutional base before adding our own dense layered classifier at the end. In fact, by using this techique we can train a very good classifier for a realtively small dataset (< 10,000 images). This is because the convnet already has a very good idea of what features to look for in an image and can find them very effectively. So, if we can determine the presence of features all the rest of the model needs to do is determine which combination of features makes a specific image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u10oZO1oXT6Y"
      },
      "source": [
        "###Fine Tuning\n",
        "When we employ the technique defined above, we will often want to tweak the final layers in our convolutional base to work better for our specific problem. This involves not touching or retraining the earlier layers in our convolutional base but only adjusting the final few. We do this because the first layers in our base are very good at extracting low level features lile lines and edges, things that are similar for any kind of image. Where the later layers are better at picking up very specific features like shapes or even eyes. If we adjust the final layers than we can look for only features relevant to our very specific problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XolyariNdj5p"
      },
      "source": [
        "##Using a Pretrained Model\n",
        "In this section we will combine the tecniques we learned above and use a pretrained model and fine tuning to classify images of dogs and cats using a small dataset.\n",
        "\n",
        "*This tutorial is based on the following guide from the TensorFlow documentation: https://www.tensorflow.org/tutorials/images/transfer_learning*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nRe9qWmgxm7"
      },
      "source": [
        "#Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "keras = tf.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUx4I_4jg2Tc"
      },
      "source": [
        "###Dataset\n",
        "We will load the *cats_vs_dogs* dataset from the modoule tensorflow_datatsets.\n",
        "\n",
        "This dataset contains (image, label) pairs where images have different dimensions and 3 color channels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuGu50NlgreO"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# split the data manually into 80% training, 10% testing, 10% validation\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_MpiQyh-as"
      },
      "source": [
        "get_label_name = metadata.features['label'].int2str  # creates a function object that we can use to get labels\n",
        "\n",
        "# display 2 images from the dataset\n",
        "for image, label in raw_train.take(5):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(get_label_name(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdodmcYiPOF"
      },
      "source": [
        "###Data Preprocessing\n",
        "Since the sizes of our images are all different, we need to convert them all to the same size. We can create a function that will do that for us below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcoKn1VUieqx"
      },
      "source": [
        "IMG_SIZE = 160 # All images will be resized to 160x160\n",
        "\n",
        "def format_example(image, label):\n",
        "  \"\"\"\n",
        "  returns an image that is reshaped to IMG_SIZE\n",
        "  \"\"\"\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwIB21lailXh"
      },
      "source": [
        "Now we can apply this function to all our images using ```.map()```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E8iqYOAipdU"
      },
      "source": [
        "train = raw_train.map(format_example)\n",
        "validation = raw_validation.map(format_example)\n",
        "test = raw_test.map(format_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QORLTVNaiqym"
      },
      "source": [
        "Let's have a look at our images now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ZIhkFPi_Pb"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)\n",
        "test_batches = test.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QxI-fOAjDzC"
      },
      "source": [
        "Now if we look at the shape of an original image vs the new image we will see it has been changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyqrCYNOjY9v"
      },
      "source": [
        "for img, label in raw_train.take(2):\n",
        "  print(\"Original shape:\", img.shape)\n",
        "\n",
        "for img, label in train.take(2):\n",
        "  print(\"New shape:\", img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMpKJ3Xbj4BW"
      },
      "source": [
        "###Picking a Pretrained Model\n",
        "The model we are going to use as the convolutional base for our model is the **MobileNet V2** developed at Google. This model is trained on 1.4 million images and has 1000 different classes.\n",
        "\n",
        "We want to use this model but only its convolutional base. So, when we load in the model, we'll specify that we don't want to load the top (classification) layer. We'll tell the model what input shape to expect and to use the predetermined weights from *imagenet* (Googles dataset).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a09os6dkokI"
      },
      "source": [
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRvMuWoFR2CO"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckYqfl7Vky3S"
      },
      "source": [
        "At this point this *base_model* will simply output a shape (32, 5, 5, 1280) tensor that is a feature extraction from our original (1, 160, 160, 3) image. The 32 means that we have 32 layers of differnt filters/features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yojo6ONzlFGF"
      },
      "source": [
        "for image, _ in train_batches.take(1):\n",
        "   pass\n",
        "\n",
        "feature_batch = base_model(image)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ2kn1P_lhsg"
      },
      "source": [
        "###Freezing the Base\n",
        "The term **freezing** refers to disabling the training property of a layer. It simply means we won’t make any changes to the weights of any layers that are frozen during training. This is important as we don't want to change the convolutional base that already has learned weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hXctqtYl8o5"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jIGFXOrl9wc"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7UJLbJ7mJzw"
      },
      "source": [
        "###Adding our Classifier\n",
        "Now that we have our base layer setup, we can add the classifier. Instead of flattening the feature map of the base layer we will use a global average pooling layer that will average the entire 5x5 area of each 2D feature map and return to us a single 1280 element vector per filter.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uUwG5wrnFD6"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejxd7rjInIRp"
      },
      "source": [
        "Finally, we will add the predicition layer that will be a single dense neuron. We can do this because we only have two classes to predict for.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA-iVZj9nH_N"
      },
      "source": [
        "prediction_layer = keras.layers.Dense(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn9G9KiFnXu6"
      },
      "source": [
        "Now we will combine these layers together in a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_IJucQNnXBK"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLYdAL2uSt_a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHepCsPXnpYZ"
      },
      "source": [
        "###Training the Model\n",
        "Now we will train and compile the model. We will use a very small learning rate to ensure that the model does not have any major changes made to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQhg2WxHnxra"
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fx9nySdoZuL"
      },
      "source": [
        "# We can evaluate the model right now to see how it does before training it on our new images\n",
        "initial_epochs = 3\n",
        "validation_steps=20\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edMXObctojl6"
      },
      "source": [
        "# Now we can train it on our images\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_batches)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUUt3AxA2lf2"
      },
      "source": [
        "model.save(\"dogs_vs_cats.h5\")  # we can save the model and reload it at anytime in the future\n",
        "new_model = tf.keras.models.load_model('dogs_vs_cats.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEiX-D2f2tvI"
      },
      "source": [
        "##Sources\n",
        "1. “Convolutional Neural Network (CNN) &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/images/cnn.\n",
        "2. “Transfer Learning with a Pretrained ConvNet &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/images/transfer_learning.\n",
        "3. Chollet François. Deep Learning with Python. Manning Publications Co., 2018.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5cjtsHP8t5Y"
      },
      "source": [
        "#Natural Language Processing using RNN\n",
        "Natural Language Processing (or NLP for short) is a discipline in computing that deals with the communication between natural (human) languages and computer languages. A common example of NLP is something like spellcheck or autocomplete. Essentially NLP is the field that focuses on how computers can understand and/or process natural/human languages.\n",
        "\n",
        "###Recurrent Neural Networks\n",
        "\n",
        "In this tutorial we will introduce a new kind of neural network that is much more capable of processing sequential data such as text or characters called a **recurrent neural network** (RNN for short).\n",
        "\n",
        "We will learn how to use a reccurent neural network to do the following:\n",
        "- Sentiment Analysis\n",
        "- Character Generation\n",
        "\n",
        "RNN's are complex and come in many different forms so in this tutorial we wil focus on how they work and the kind of problems they are best suited for.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur_FQq-Q-fxC"
      },
      "source": [
        "## Sequence Data\n",
        "In the previous tutorials we focused on data that we could represent as one static data point where the notion of time or step was irrelevant. Take for example our image data, it was simply a tensor of shape (width, height, channels). That data doesn't change or care about the notion of time.\n",
        "\n",
        "In this tutorial we will look at sequences of text and learn how we can encode them in a meaningful way. Unlike images, sequence data such as long chains of text, weather patterns, videos and really anything where the notion of a step or time is relevant needs to be processed and handled in a special way.\n",
        "\n",
        "But what do I mean by sequences and why is text data a sequence? Well that's a good question. Since textual data contains many words that follow in a very specific and meaningful order, we need to be able to keep track of each word and when it occurs in the data. Simply encoding say an entire paragraph of text into one data point wouldn't give us a very meaningful picture of the data and would be very difficult to do anything with. This is why we treat text as a sequence and process one word at a time. We will keep track of where each of these words appear and use that information to try to understand the meaning of peices of text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gQHK4V4e2wl"
      },
      "source": [
        "##Encoding Text\n",
        "As we know machine learning models and neural networks don't take raw text data as an input. This means we must somehow encode our textual data to numeric values that our models can understand. There are many different ways of doing this and we will look at a few examples below.\n",
        "\n",
        "Before we get into the different encoding/preprocessing methods let's understand the information we can get from textual data by looking at the following two movie reviews.\n",
        "\n",
        "```I thought the movie was going to be bad, but it was actually amazing!```\n",
        "\n",
        "```I thought the movie was going to be amazing, but it was actually bad!```\n",
        "\n",
        "Although these two setences are very similar we know that they have very different meanings. This is because of the **ordering** of words, a very important property of textual data.\n",
        "\n",
        "Now keep that in mind while we consider some different ways of encoding our textual data.\n",
        "\n",
        "###Bag of Words\n",
        "The first and simplest way to encode our data is to use something called **bag of words**. This is a pretty easy technique where each word in a sentence is encoded with an integer and thrown into a collection that does not maintain the order of the words but does keep track of the frequency. Have a look at the python function below that encodes a string of text into bag of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KiCCBsIkMHi"
      },
      "source": [
        "vocab = {}  # maps word to integer representing it\n",
        "word_encoding = 1\n",
        "def bag_of_words(text):\n",
        "  global word_encoding\n",
        "\n",
        "  words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\n",
        "  bag = {}  # stores all of the encodings and their frequency\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      encoding = vocab[word]  # get encoding from vocab\n",
        "    else:\n",
        "      vocab[word] = word_encoding\n",
        "      encoding = word_encoding\n",
        "      word_encoding += 1\n",
        "\n",
        "    if encoding in bag:\n",
        "      bag[encoding] += 1\n",
        "    else:\n",
        "      bag[encoding] = 1\n",
        "\n",
        "  return bag\n",
        "\n",
        "text = \"this is a test to see if this test will work is is test a a\"\n",
        "bag = bag_of_words(text)\n",
        "print(bag)\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hEvstSBl1gy"
      },
      "source": [
        "This isn't really the way we would do this in practice, but I hope it gives you an idea of how bag of words works. Notice that we've lost the order in which words appear. In fact, let's look at how this encoding works for the two sentences we showed above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miYshfvzmJ0H"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
        "\n",
        "pos_bag = bag_of_words(positive_review)\n",
        "neg_bag = bag_of_words(negative_review)\n",
        "\n",
        "print(\"Positive:\", pos_bag)\n",
        "print(\"Negative:\", neg_bag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUKTycffmu1k"
      },
      "source": [
        "###Integer Encoding\n",
        "The next technique we will look at is called **integer encoding**. This involves representing each word or character in a sentence as a unique integer and maintaining the order of these words. This should hopefully fix the problem we saw before were we lost the order of words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKY4y_tjnUEW"
      },
      "source": [
        "vocab = {}\n",
        "word_encoding = 1\n",
        "def one_hot_encoding(text):\n",
        "  global word_encoding\n",
        "\n",
        "  words = text.lower().split(\" \")\n",
        "  encoding = []\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      code = vocab[word]\n",
        "      encoding.append(code)\n",
        "    else:\n",
        "      vocab[word] = word_encoding\n",
        "      encoding.append(word_encoding)\n",
        "      word_encoding += 1\n",
        "\n",
        "  return encoding\n",
        "\n",
        "text = \"this is a test to see if this test will work is is test a a\"\n",
        "encoding = one_hot_encoding(text)\n",
        "print(encoding)\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOrLG9Bin0Zv"
      },
      "source": [
        "And now let's have a look at one hot encoding on our movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S-GNjotn-Br"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
        "\n",
        "pos_encode = one_hot_encoding(positive_review)\n",
        "neg_encode = one_hot_encoding(negative_review)\n",
        "\n",
        "print(\"Positive:\", pos_encode)\n",
        "print(\"Negative:\", neg_encode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC9UYV4vpq6Y"
      },
      "source": [
        "Much better, now we are keeping track of the order of words and we can tell where each occurs. But this still has a few issues with it. Ideally when we encode words, we would like similar words to have similar labels and different words to have very different labels. For example, the words happy and joyful should probably have very similar labels so we can determine that they are similar. While words like horrible and amazing should probably have very different labels. The method we looked at above won't be able to do something like this for us. This could mean that the model will have a very difficult time determing if two words are similar or not which could result in some pretty drastic performace impacts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRZ73YCqqiw9"
      },
      "source": [
        "###Word Embeddings\n",
        "Luckily there is a third method that is far superior, **word embeddings**. This method keeps the order of words intact as well as encodes similar words with very similar labels. It attempts to not only encode the frequency and order of words but the meaning of those words in the sentence. It encodes each word as a dense vector that represents its context in the sentence.\n",
        "\n",
        "Unlike the previous techniques word embeddings are learned by looking at many different training examples. You can add what's called an *embedding layer* to the beggining of your model and while your model trains your embedding layer will learn the correct embeddings for words. You can also use pretrained embedding layers.\n",
        "\n",
        "This is the technique we will use for our examples and its implementation will be showed later on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehig3qliuUzk"
      },
      "source": [
        "##Recurrent Neural Networks (RNN's)\n",
        "Now that we've learned a little bit about how we can encode text it's time to dive into recurrent neural networks. Up until this point we have been using something called **feed-forward** neural networks. This simply means that all our data is fed forwards (all at once) from left to right through the network. This was fine for the problems we considered before but won't work very well for processing text. After all, even we (humans) don't process text all at once. We read word by word from left to right and keep track of the current meaning of the sentence so we can understand the meaning of the next word. Well this is exaclty what a recurrent neural network is designed to do. When we say recurrent neural network all we really mean is a network that contains a loop. A RNN will process one word at a time while maintaining an internal memory of what it's already seen. This will allow it to treat words differently based on their order in a sentence and to slowly build an understanding of the entire input, one word at a time.\n",
        "\n",
        "This is why we are treating our text data as a sequence! So that we can pass one word at a time to the RNN.\n",
        "\n",
        "Let's have a look at what a recurrent layer might look like.\n",
        "\n",
        "![alt text](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
        "*Source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/*\n",
        "\n",
        "Let's define what all these variables stand for before we get into the explination.\n",
        "\n",
        "**h<sub>t</sub>** output at time t\n",
        "\n",
        "**x<sub>t</sub>** input at time t\n",
        "\n",
        "**A** Recurrent Layer (loop)\n",
        "\n",
        "What this diagram is trying to illustrate is that a recurrent layer processes words or input one at a time in a combination with the output from the previous iteration. So, as we progress further in the input sequence, we build a more complex understanding of the text as a whole.\n",
        "\n",
        "What we've just looked at is called a **simple RNN layer**. It can be effective at processing shorter sequences of text for simple problems but has many downfalls associated with it. One of them being the fact that as text sequences get longer it gets increasingly difficult for the network to understand the text properly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo3WY-e86zX2"
      },
      "source": [
        "##LSTM\n",
        "The layer we dicussed in depth above was called a *simpleRNN*. However, there does exist some other recurrent layers (layers that contain a loop) that work much better than a simple RNN layer. The one we will talk about here is called LSTM (Long Short-Term Memory). This layer works very similarily to the simpleRNN layer but adds a way to access inputs from any timestep in the past. Whereas in our simple RNN layer input from previous timestamps gradually disappeared as we got further through the input. With a LSTM we have a long-term memory data structure storing all the previously seen inputs as well as when we saw them. This allows for us to access any previous value we want at any point in time. This adds to the complexity of our network and allows it to discover more useful relationships between inputs and when they appear.\n",
        "\n",
        "For the purpose of this course we will refrain from going any further into the math or details behind how these layers work.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRGOx6_v4eZ_"
      },
      "source": [
        "##Sentiment Analysis\n",
        "And now time to see a recurrent neural network in action. For this example, we are going to do something called sentiment analysis.\n",
        "\n",
        "The formal definition of this term from Wikipedia is as follows:\n",
        "\n",
        "*the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral.*\n",
        "\n",
        "The example we’ll use here is classifying movie reviews as either postive, negative or neutral.\n",
        "\n",
        "*This guide is based on the following tensorflow tutorial: https://www.tensorflow.org/tutorials/text/text_classification_rnn*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RACGE5Ypt5u9"
      },
      "source": [
        "###Movie Review Dataset\n",
        "Well start by loading in the IMDB movie review dataset from keras. This dataset contains 25,000 reviews from IMDB where each one is already preprocessed and has a label as either positive or negative. Each review is encoded by integers that represents how common a word is in the entire dataset. For example, a word encoded by the integer 3 means that it is the 3rd most common word in the dataset.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdsus1kyXWC8"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh6lOpcQ9sIZ"
      },
      "source": [
        "# Lets look at one review\n",
        "train_data[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAtZHE9-eQ07"
      },
      "source": [
        "###More Preprocessing\n",
        "If we have a look at some of our loaded in reviews, we'll notice that they are different lengths. This is an issue. We cannot pass different length data into our neural network. Therefore, we must make each review the same length. To do this we will follow the procedure below:\n",
        "- if the review is greater than 250 words then trim off the extra words\n",
        "- if the review is less than 250 words add the necessary amount of 0's to make it equal to 250.\n",
        "\n",
        "Luckily for us keras has a function that can do this for us:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWGGcBIpjrMu"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8_jPL_Kkr-a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyeQCk3LlK6V"
      },
      "source": [
        "###Training\n",
        "Now it's time to compile and train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKEMjaIulPBe"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3buYlkkhoK93"
      },
      "source": [
        "And we'll evaluate the model on our training data to see how well it performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KImNMWTDoJaQ"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGrBRC4YCObV"
      },
      "source": [
        "###Making Predictions\n",
        "Now let’s use our network to make predictions on our own reviews.\n",
        "\n",
        "Since our reviews are encoded well need to convert any review that we write into that form so the network can understand it. To do that well load the encodings from the dataset and use them to encode our own data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onu8leY4Cn9z"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKna3vxmFwrB"
      },
      "source": [
        "# while were at it lets make a decode function\n",
        "\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "\n",
        "print(decode_integers(encoded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8nyrr00HPZF"
      },
      "source": [
        "# now time to make a prediction\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred)\n",
        "  print(result[0])\n",
        "\n",
        "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01BJLcGb4ZqK"
      },
      "source": [
        "##RNN Play Generator\n",
        "\n",
        "Now time for one of the coolest examples we've seen so far. We are going to use a RNN to generate a play. We will simply show the RNN an example of something we want it to recreate and it will learn how to write a version of it on its own. We'll do this using a character predictive model that will take as input a variable length sequence and predict the next character. We can use the model many times in a row with the output from the last predicition as the input for the next call to generate a sequence.\n",
        "\n",
        "\n",
        "*This guide is based on the following: https://www.tensorflow.org/tutorials/text/text_generation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fju7i1FKrK_G"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F48c-EctQ378"
      },
      "source": [
        "###Dataset\n",
        "For this example, we only need one peice of training data. In fact, we can write our own poem or play and pass that to the network for training if we'd like. However, to make things easy we'll use an extract from a shakesphere play.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdRcVIhtRGlF"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlSVGd5ACkZe"
      },
      "source": [
        "###Loading Your Own Data\n",
        "To load your own data, you'll need to upload a file from the dialog below. Then you'll need to follow the steps from above but load in this new file instead.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFYFwbJOC3bP"
      },
      "source": [
        "from google.colab import files\n",
        "path_to_file = list(files.upload().keys())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtJMEqQyRhAk"
      },
      "source": [
        "###Read Contents of File\n",
        "Let's look at the contents of the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n4oovOMRnP7"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUxQVl7Rt10"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vt8Vpe0RvaJ"
      },
      "source": [
        "###Encoding\n",
        "Since this text isn't encoded yet well need to do that ourselves. We are going to encode each unique character as a different integer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7AZNI7aRz6y"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i5kvmX_SLW4"
      },
      "source": [
        "# lets look at how part of our text is encoded\n",
        "print(\"Text:\", text[:13])\n",
        "print(\"Encoded:\", text_to_int(text[:13]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDvD5kqTWwOn"
      },
      "source": [
        "And here we will make a function that can convert our numeric values to text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af52YChSW5hX"
      },
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_49cl6uS0r-"
      },
      "source": [
        "###Creating Training Examples\n",
        "Remember our task is to feed the model a sequence and have it return to us the next character. This means we need to split our text data from above into many shorter sequences that we can pass to the model as training examples.\n",
        "\n",
        "The training examples we will prepapre will use a *seq_length* sequence as input and a *seq_length* sequence as the output where that sequence is the original sequence shifted one letter to the right. For example:\n",
        "\n",
        "```input: Hell | output: ello```\n",
        "\n",
        "Our first step will be to create a stream of characters from our text data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBkXz9fjUQHW"
      },
      "source": [
        "seq_length = 100  # length of sequence for a training example\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqmxfT7gVGlr"
      },
      "source": [
        "Next we can use the batch method to turn this stream of characters into batches of desired length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi0xaPB_VOJl"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxo1Dig_VvV1"
      },
      "source": [
        "Now we need to use these sequences of length 101 and split them into input and output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03zKVHTvV0Km"
      },
      "source": [
        "def split_input_target(chunk):  # for the example: hello\n",
        "    input_text = chunk[:-1]  # hell\n",
        "    target_text = chunk[1:]  # ello\n",
        "    return input_text, target_text  # hell, ello\n",
        "\n",
        "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p_y2YmgWbnc"
      },
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6OxuFKVXpwK"
      },
      "source": [
        "Finally we need to make training batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRsKcjhXXuoD"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6YRmZLtX0d0"
      },
      "source": [
        "###Building the Model\n",
        "Now it is time to build the model. We will use an embedding layer a LSTM and one dense layer that contains a node for each unique character in our training data. The dense layer will give us a probability distribution over all nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v_P2dEic4qt"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gfnHBUOvPqE"
      },
      "source": [
        "###Creating a Loss Function\n",
        "Now we are going to create our own loss function for this problem. This is because our model will output a (64, sequence_length, 65) shaped tensor that represents the probability distribution of each character at each timestep for every sequence in the batch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdvEqlwc6_q0"
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQS5KXwi7_NX"
      },
      "source": [
        "# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n",
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA1Zhop28V9n"
      },
      "source": [
        "# lets examine one prediction\n",
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)\n",
        "# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbIoe7Ei8q3q"
      },
      "source": [
        "# and finally well look at a prediction at the first timestep\n",
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)\n",
        "# and of course its 65 values representing the probabillity of each character occuring next"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlEYM1H995gR"
      },
      "source": [
        "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars  # and this is what the model predicted for training sequence 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcCBfPjN9Cnp"
      },
      "source": [
        "So now we need to create a loss function that can compare that output to the expected output and give us some numeric value representing how close the two were."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOw23fWq9D9O"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcg75GwXgW81"
      },
      "source": [
        "###Compiling the Model\n",
        "At this point we can think of our problem as a classification problem where the model predicts the probabillity of each unique letter coming next.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g6o7zA_hAiS"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgDKr4yvjLPI"
      },
      "source": [
        "###Creating Checkpoints\n",
        "Now we are going to setup and configure our model to save checkpoinst as it trains. This will allow us to load our model from a checkpoint and continue training it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7aMushYjSpy"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7acPvGja5c"
      },
      "source": [
        "###Training\n",
        "Finally, we will start training the model.\n",
        "\n",
        "**If this is taking a while go to Runtime > Change Runtime Type and choose \"GPU\" under hardware accelerator.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PAgrwMjZ4_"
      },
      "source": [
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GhoHJVtmTsz"
      },
      "source": [
        "###Loading the Model\n",
        "We'll rebuild the model from a checkpoint using a batch_size of 1 so that we can feed one peice of text to the model and have it make a prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPSto3uimSKp"
      },
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boEJvy_vjLJQ"
      },
      "source": [
        "Once the model is finished training, we can find the **lastest checkpoint** that stores the models weights using the following line.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZIEZWE4mNKl"
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmPPtbaTKF8d"
      },
      "source": [
        "We can load **any checkpoint** we want by specifying the exact file to load."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ_5p0ehKFDn"
      },
      "source": [
        "checkpoint_num = 10\n",
        "model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\" + str(checkpoint_num)))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaZWalEeAxQN"
      },
      "source": [
        "###Generating Text\n",
        "Now we can use the lovely function provided by tensorflow to generate some text using any starting string we'd like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPSALdQXA3l3"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 800\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAJqhD9AA5mF"
      },
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw-1eDE54yQo"
      },
      "source": [
        "##Sources\n",
        "\n",
        "1. Chollet François. Deep Learning with Python. Manning Publications Co., 2018.\n",
        "2. “Text Classification with an RNN &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/text/text_classification_rnn.\n",
        "3. “Text Generation with an RNN &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/text/text_generation.\n",
        "4. “Understanding LSTM Networks.” Understanding LSTM Networks -- Colah's Blog, https://colah.github.io/posts/2015-08-Understanding-LSTMs/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ADWvu7NKN2r"
      },
      "source": [
        "##Reinforcement Learning\n",
        "The next and final topic in this course covers *Reinforcement Learning*. This technique is different than many of the other machine learning techniques we have seen earlier and has many applications in training agents (an AI) to interact with enviornments like games. Rather than feeding our machine learning model millions of examples we let our model come up with its own examples by exploring an enviornemt. The concept is simple. Humans learn by exploring and learning from mistakes and past experiences so let's have our computer do the same.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGCR3JWQLaQb"
      },
      "source": [
        "###Terminology\n",
        "Before we dive into explaining reinforcement learning we need to define a few key peices of terminology.\n",
        "\n",
        "**Enviornemt** In reinforcement learning tasks we have a notion of the enviornment. This is what our *agent* will explore. An example of an enviornment in the case of training an AI to play say a game of mario would be the level we are training the agent on.\n",
        "\n",
        "**Agent** an agent is an entity that is exploring the enviornment. Our agent will interact and take different actions within the enviornment. In our mario example the mario character within the game would be our agent.\n",
        "\n",
        "**State** always our agent will be in what we call a *state*. The state simply tells us about the status of the agent. The most common example of a state is the location of the agent within the enviornment. Moving locations would change the agents state.\n",
        "\n",
        "**Action** any interaction between the agent and enviornment would be considered an action. For example, moving to the left or jumping would be an action. An action may or may not change the current *state* of the agent. In fact, the act of doing nothing is an action as well! The action of say not pressing a key if we are using our mario example.\n",
        "\n",
        "**Reward** every action that our agent takes will result in a reward of some magnitude (positive or negative). The goal of our agent will be to maximize its reward in an enviornment. Sometimes the reward will be clear, for example if an agent performs an action which increases their score in the enviornment we could say they've recieved a positive reward. If the agent were to perform an action which results in them losing score or possibly dying in the enviornment then they would recieve a negative reward.\n",
        "\n",
        "The most important part of reinforcement learning is determing how to reward the agent. After all, the goal of the agent is to maximize its rewards. This means we should reward the agent appropiatly such that it reaches the desired goal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoOJy9s4ZJJt"
      },
      "source": [
        "###Q-Learning\n",
        "Now that we have a vague idea of how reinforcement learning works it's time to talk about a specific technique in reinforcement learning called *Q-Learning*.\n",
        "\n",
        "Q-Learning is a simple yet quite powerful technique in machine learning that involves learning a matrix of action-reward values. This matrix is often reffered to as a Q-Table or Q-Matrix. The matrix is in shape (number of possible states, number of possible actions) where each value at matrix[n, m] represents the agents expected reward given they are in state n and take action m. The Q-learning algorithm defines the way we update the values in the matrix and decide what action to take at each state. The idea is that after a succesful training/learning of this Q-Table/matrix we can determine the action an agent should take in any state by looking at that states row in the matrix and taking the maximium value column as the action.\n",
        "\n",
        "**Consider this example.**\n",
        "\n",
        "Let's say A1-A4 are the possible actions and we have 3 states represented by each row (state 1 - state 3).\n",
        "\n",
        "| A1  | A2  | A3  | A4  |\n",
        "|:--: |:--: |:--: |:--: |\n",
        "|  0  |  0  | 10  |  5  |\n",
        "|  5  | 10  |  0  |  0  |\n",
        "| 10  |  5  |  0  |  0  |\n",
        "\n",
        "If that was our Q-Table/matrix then the following would be the preffered actions in each state.\n",
        "\n",
        "> State 1: A3\n",
        "\n",
        "> State 2: A2\n",
        "\n",
        "> State 3: A1\n",
        "\n",
        "We can see that this is because the values in each of those columns are the highest for those states!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5uLpN1yemTx"
      },
      "source": [
        "###Learning the Q-Table\n",
        "So that's simple, right? Now how do we create this table and find those values. Well this is where we will dicuss how the Q-Learning algorithm updates the values in our Q-Table.\n",
        "\n",
        "I'll start by noting that our Q-Table starts of with all 0 values. This is because the agent has yet to learn anything about the enviornment.\n",
        "\n",
        "Our agent learns by exploring the enviornment and observing the outcome/reward from each action it takes in each state. But how does it know what action to take in each state? There are two ways that our agent can decide on which action to take.\n",
        "1. Randomly picking a valid action\n",
        "2. Using the current Q-Table to find the best action.\n",
        "\n",
        "Near the beginning of our agents learning it will mostly take random actions in order to explore the enviornment and enter many different states. As it starts to explore more of the enviornment it will start to gradually rely more on it's learned values (Q-Table) to take actions. This means that as our agent explores more of the enviornment it will develop a better understanding and start to take \"correct\" or better actions more often. It's important that the agent has a good balance of taking random actions and using learned values to ensure it does get trapped in a local maximum.\n",
        "\n",
        "After each new action our agent wil record the new state (if any) that it has entered and the reward that it recieved from taking that action. These values will be used to update the Q-Table. The agent will stop taking new actions only once a certain time limit is reached or it has acheived the goal or reached the end of the enviornment.\n",
        "\n",
        "####Updating Q-Values\n",
        "The formula for updating the Q-Table after each action is as follows:\n",
        "> $ Q[state, action] = Q[state, action] + \\alpha * (reward + \\gamma * max(Q[newState, :]) - Q[state, action]) $\n",
        "\n",
        "- $\\alpha$ stands for the **Learning Rate**\n",
        "\n",
        "- $\\gamma$ stands for the **Discount Factor**\n",
        "\n",
        "####Learning Rate $\\alpha$\n",
        "The learning rate $\\alpha$ is a numeric constant that defines how much change is permitted on each QTable update. A high learning rate means that each update will introduce a large change to the current state-action value. A small learning rate means that each update has a more subtle change. Modifying the learning rate will change how the agent explores the enviornment and how quickly it determines the final values in the QTable.\n",
        "\n",
        "####Discount Factor $\\gamma$\n",
        "Discount factor also know as gamma ($\\gamma$) is used to balance how much focus is put on the current and future reward. A high discount factor means that future rewards will be considered more heavily.\n",
        "\n",
        "<br/>\n",
        "<p>To perform updates on this table we will let the agent explpore the enviornment for a certain period of time and use each of its actions to make an update. Slowly we should start to notice the agent learning and choosing better actions. </p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwIl0sJgmu4D"
      },
      "source": [
        "##Q-Learning Example\n",
        "For this example we will use the Q-Learning algorithm to train an agent to navigate a popular enviornment from the [Open AI Gym](https://gym.openai.com/). The Open AI Gym was developed so programmers could practice machine learning using unique enviornments. Intersting fact, Elon Musk is one of the founders of OpenAI!\n",
        "\n",
        "Let's start by looking at what Open AI Gym is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSETF0zqokYr"
      },
      "source": [
        "import gym   # all you have to do to import and use open ai gym!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cH3AmCzotO1"
      },
      "source": [
        "Once you import gym you can load an enviornment using the line ```gym.make(\"enviornment\")```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKN1ScBco3dp"
      },
      "source": [
        "env = gym.make('FrozenLake-v0')  # we are going to use the FrozenLake enviornment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SvSlmVwo8cY"
      },
      "source": [
        "There are a few other commands that can be used to interact and get information about the enviornment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF3icIeapFct"
      },
      "source": [
        "print(env.observation_space.n)   # get number of states\n",
        "print(env.action_space.n)   # get number of actions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc9cwp03pQVn"
      },
      "source": [
        "env.reset()  # reset enviornment to default state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sngyjPDapUt7"
      },
      "source": [
        "action = env.action_space.sample()  # get a random action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeEfi8xypXya"
      },
      "source": [
        "new_state, reward, done, info = env.step(action)  # take action, notice it returns information about the action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1W3D81ipdaS"
      },
      "source": [
        "env.render()   # render the GUI for the enviornment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmW6HAbQp01f"
      },
      "source": [
        "###Frozen Lake Enviornment\n",
        "Now that we have a basic understanding of how the gym enviornment works it's time to discuss the specific problem we will be solving.\n",
        "\n",
        "The enviornment we loaded above ```FrozenLake-v0``` is one of the simplest enviornments in Open AI Gym. The goal of the agent is to navigate a frozen lake and find the Goal without falling through the ice (render the enviornment above to see an example).\n",
        "\n",
        "There are:\n",
        "- 16 states (one for each square)\n",
        "- 4 possible actions (LEFT, RIGHT, DOWN, UP)\n",
        "- 4 different types of blocks (F: frozen, H: hole, S: start, G: goal)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlWoK75ZrK2b"
      },
      "source": [
        "###Building the Q-Table\n",
        "The first thing we need to do is build an empty Q-Table that we can use to store and update our values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r767K4s0rR2p"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "env = gym.make('FrozenLake-v0')\n",
        "STATES = env.observation_space.n\n",
        "ACTIONS = env.action_space.n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAzMWGatrVIk"
      },
      "source": [
        "Q = np.zeros((STATES, ACTIONS))  # create a matrix with all 0 values\n",
        "Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc_h8tLSrpmc"
      },
      "source": [
        "###Constants\n",
        "As we discussed we need to define some constants that will be used to update our Q-Table and tell our agent when to stop training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FQapdnnr6P1"
      },
      "source": [
        "EPISODES = 2000 # how many times to run the enviornment from the beginning\n",
        "MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n",
        "\n",
        "LEARNING_RATE = 0.81  # learning rate\n",
        "GAMMA = 0.96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxrAj91rsMfm"
      },
      "source": [
        "###Picking an Action\n",
        "Remember that we can pick an action using one of two methods:\n",
        "1. Randomly picking a valid action\n",
        "2. Using the current Q-Table to find the best action.\n",
        "\n",
        "Here we will define a new value $\\epsilon$ that will tell us the probabillity of selecting a random action. This value will start off very high and slowly decrease as the agent learns more about the enviornment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUAQVyX0sWDb"
      },
      "source": [
        "epsilon = 0.9  # start with a 90% chance of picking a random action\n",
        "\n",
        "# code to pick action\n",
        "if np.random.uniform(0, 1) < epsilon:  # we will check if a randomly selected value is less than epsilon.\n",
        "    action = env.action_space.sample()  # take random action\n",
        "else:\n",
        "    action = np.argmax(Q[state, :])  # use Q table to pick best action based on current values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n-i0B7Atige"
      },
      "source": [
        "###Updating Q Values\n",
        "The code below implements the formula discussed above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r7R1W6Qtnh8"
      },
      "source": [
        "Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[new_state, :]) - Q[state, action])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__afaD62uh8G"
      },
      "source": [
        "###Putting it Together\n",
        "Now that we know how to do some basic things we can combine these together to create our Q-Learning algorithm,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGiYCiNuutHz"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "env = gym.make('FrozenLake-v0')\n",
        "STATES = env.observation_space.n\n",
        "ACTIONS = env.action_space.n\n",
        "\n",
        "Q = np.zeros((STATES, ACTIONS))\n",
        "\n",
        "EPISODES = 1500 # how many times to run the enviornment from the beginning\n",
        "MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n",
        "\n",
        "LEARNING_RATE = 0.81  # learning rate\n",
        "GAMMA = 0.96\n",
        "\n",
        "RENDER = False # if you want to see training set to true\n",
        "\n",
        "epsilon = 0.9\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFRtn5dUu5ZI"
      },
      "source": [
        "rewards = []\n",
        "for episode in range(EPISODES):\n",
        "\n",
        "  state = env.reset()\n",
        "  for _ in range(MAX_STEPS):\n",
        "\n",
        "    if RENDER:\n",
        "      env.render()\n",
        "\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      action = np.argmax(Q[state, :])\n",
        "\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "    Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[next_state, :]) - Q[state, action])\n",
        "\n",
        "    state = next_state\n",
        "\n",
        "    if done:\n",
        "      rewards.append(reward)\n",
        "      epsilon -= 0.001\n",
        "      break  # reached goal\n",
        "\n",
        "print(Q)\n",
        "print(f\"Average reward: {sum(rewards)/len(rewards)}:\")\n",
        "# and now we can see our Q values!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo-tNznd65US"
      },
      "source": [
        "# we can plot the training progress and see how the agent improved\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_average(values):\n",
        "  return sum(values)/len(values)\n",
        "\n",
        "avg_rewards = []\n",
        "for i in range(0, len(rewards), 100):\n",
        "  avg_rewards.append(get_average(rewards[i:i+100]))\n",
        "\n",
        "plt.plot(avg_rewards)\n",
        "plt.ylabel('average reward')\n",
        "plt.xlabel('episodes (100\\'s)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy4YH2m9s1ww"
      },
      "source": [
        "##Sources\n",
        "1. Violante, Andre. “Simple Reinforcement Learning: Q-Learning.” Medium, Towards Data Science, 1 July 2019, https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56.\n",
        "\n",
        "2. Openai. “Openai/Gym.” GitHub, https://github.com/openai/gym/wiki/FrozenLake-v0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPgo18-N1gSi"
      },
      "source": [
        "# 01. Neural Network Regression with TensorFlow\n",
        "\n",
        "There are many definitions for a [regression problem](https://en.wikipedia.org/wiki/Regression_analysis) but in our case, we're going to simplify it to be: predicting a number.\n",
        "\n",
        "For example, you might want to:\n",
        "- Predict the selling price of houses given information about them (such as number of rooms, size, number of bathrooms).\n",
        "- Predict the coordinates of a bounding box of an item in an image.\n",
        "- Predict the cost of medical insurance for an individual given their demographics (age, sex, gender, race).\n",
        "\n",
        "In this notebook, we're going to set the foundations for how you can take a sample of inputs (this is your data), build a neural network to discover patterns in those inputs and then make a prediction (in the form of a number) based on those inputs.\n",
        "\n",
        "## What we're going to cover\n",
        "\n",
        "Specifically, we're going to go through doing the following with TensorFlow:\n",
        "- Architecture of a regression model\n",
        "- Input shapes and output shapes\n",
        "  - `X`: features/data (inputs)\n",
        "  - `y`: labels (outputs)\n",
        "- Creating custom data to view and fit\n",
        "- Steps in modelling\n",
        "  - Creating a model\n",
        "  - Compiling a model\n",
        "    - Defining a loss function\n",
        "    - Setting up an optimizer\n",
        "    - Creating evaluation metrics\n",
        "  - Fitting a model (getting it to find patterns in our data)\n",
        "- Evaluating a model\n",
        "  - Visualizng the model (\"visualize, visualize, visualize\")\n",
        "  - Looking at training curves\n",
        "  - Compare predictions to ground truth (using our evaluation metrics)\n",
        "- Saving a model (so we can use it later)\n",
        "- Loading a model\n",
        "\n",
        "Don't worry if none of these make sense now, we're going to go through each.\n",
        "\n",
        "## How you can use this notebook\n",
        "\n",
        "You can read through the descriptions and the code (it should all run), but there's a better option.\n",
        "\n",
        "Write all of the code yourself.\n",
        "\n",
        "Yes. I'm serious. Create a new notebook, and rewrite each line by yourself. Investigate it, see if you can break it, why does it break?\n",
        "\n",
        "You don't have to write the text descriptions but writing the code yourself is a great way to get hands-on experience.\n",
        "\n",
        "Don't worry if you make mistakes, we all do. The way to get better and make less mistakes is to **write more code**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etAu7oCZ8r_G"
      },
      "source": [
        "## Typical architecture of a regresison neural network\n",
        "\n",
        "The word *typical* is on purpose.\n",
        "\n",
        "Why?\n",
        "\n",
        "Because there are many different ways (actually, there's almost an infinite number of ways) to write neural networks.\n",
        "\n",
        "But the following is a generic setup for ingesting a collection of numbers, finding patterns in them and then outputting some kind of target number.\n",
        "\n",
        "Yes, the previous sentence is vague but we'll see this in action shortly.\n",
        "\n",
        "| **Hyperparameter** | **Typical value** |\n",
        "| --- | --- |\n",
        "| Input layer shape | Same shape as number of features (e.g. 3 for # bedrooms, # bathrooms, # car spaces in housing price prediction) |\n",
        "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |\n",
        "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
        "| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |\n",
        "| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) |\n",
        "| Output activation | None, ReLU, logistic/tanh |\n",
        "| Loss function | [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (mean square error) or [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) (mean absolute error)/Huber (combination of MAE/MSE) if outliers |\n",
        "| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) |\n",
        "\n",
        "*Table 1: Typical architecture of a regression network. Source: Adapted from page 293 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aurélien Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*\n",
        "\n",
        "Again, if you're new to neural networks and deep learning in general, much of the above table won't make sense. But don't worry, we'll be getting hands-on with all of it soon.\n",
        "\n",
        "> 🔑 **Note:** A **hyperparameter** in machine learning is something a data analyst or developer can set themselves, where as a **parameter** usually describes something a model learns on its own (a value not explicitly set by an analyst).\n",
        "\n",
        "Okay, enough talk, let's get started writing code.\n",
        "\n",
        "To use TensorFlow, we'll import it as the common alias `tf` (short for TensorFlow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMqsqKpk7TrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71dcbb23-77b4-4032-9392-d8f93ee8262a"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__) # check the version (should be 2.x+)\n",
        "\n",
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "Notebook last run (end-to-end): 2023-05-07 23:10:01.302908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8clMYxrF6Mzv"
      },
      "source": [
        "## Creating data to view and fit\n",
        "\n",
        "Since we're working on a **regression problem** (predicting a number) let's create some linear data (a straight line) to model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G43tWFof6i7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "6ccaf308-ea75-4fc6-c049-60587705204e"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNCXxHnF6jjZ"
      },
      "source": [
        "## Regression input shapes and output shapes\n",
        "\n",
        "One of the most important concepts when working with neural networks are the input and output shapes.\n",
        "\n",
        "The **input shape** is the shape of your data that goes into the model.\n",
        "\n",
        "The **output shape** is the shape of your data you want to come out of your model.\n",
        "\n",
        "These will differ depending on the problem you're working on.\n",
        "\n",
        "Neural networks accept numbers and output numbers. These numbers are typically represented as tensors (or arrays).\n",
        "\n",
        "Before, we created data using NumPy arrays, but we could do the same with tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrXQ3m0prWXa",
        "outputId": "023e18d3-1c67-4802-c52b-006649b7321f"
      },
      "source": [
        "# Example input and output shapes of a regression model\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi3VWKH6sRrZ",
        "outputId": "cc06303a-00fd-4eb1-b7a7-c4dd8c5c670f"
      },
      "source": [
        "house_info.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOxyr9sR6m9X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "8615828f-8811-4bdd-f69d-bca7575977fe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features (using tensors)\n",
        "X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels (using tensors)\n",
        "y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaPxco6E9i1_"
      },
      "source": [
        "Our goal here will be to use `X` to predict `y`.\n",
        "\n",
        "So our **input** will be `X` and our **output** will be `y`.\n",
        "\n",
        "Knowing this, what do you think our input and output shapes will be?\n",
        "\n",
        "Let's take a look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1oT1gmB9iX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f1666a-7fcd-4dd0-d7a2-37219c892dce"
      },
      "source": [
        "# Take a single example of X\n",
        "input_shape = X[0].shape\n",
        "\n",
        "# Take a single example of y\n",
        "output_shape = y[0].shape\n",
        "\n",
        "input_shape, output_shape # these are both scalars (no shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dag5y4MPaTmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02fad51d-1fb9-4a09-e62d-52cdd99bd030"
      },
      "source": [
        "# Let's take a look at the single examples invidually\n",
        "X[0], y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=-7.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=3.0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKtihU57_cOY"
      },
      "source": [
        "In our case, we're trying to build a model to predict the pattern between `X[0]` equalling `-7.0` and `y[0]` equalling `3.0`.\n",
        "\n",
        "So now we get our answer, we're trying to use 1 `X` value to predict 1 `y` value.\n",
        "\n",
        "You might be thinking, \"this seems pretty complicated for just predicting a straight line...\".\n",
        "\n",
        "And you'd be right.\n",
        "\n",
        "But the concepts we're covering here, the concepts of input and output shapes to a model are fundamental.\n",
        "\n",
        "In fact, they're probably two of the things you'll spend the most time on when you work with neural networks: **making sure your input and outputs are in the correct shape**.\n",
        "\n",
        "If it doesn't make sense now, we'll see plenty more examples later on (soon you'll notice the input and output shapes can be almost anything you can imagine).\n",
        "\n",
        "![example of input and output shapes for a housing price prediction problem](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/01-input-and-output-shapes-housing-prices.png)\n",
        "*If you were working on building a machine learning algorithm for predicting housing prices, your inputs may be number of bedrooms, number of bathrooms and number of garages, giving you an input shape of 3 (3 different features). And since you're trying to predict the price of the house, your output shape would be 1.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhAIqjrn6olF"
      },
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "Now we know what data we have as well as the input and output shapes, let's see how we'd build a neural network to model it.\n",
        "\n",
        "In TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n",
        "\n",
        "1. **Creating a model** - piece together the layers of a neural network yourself (using the [Functional](https://www.tensorflow.org/guide/keras/functional) or [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)) or import a previously built model (known as transfer learning).\n",
        "2. **Compiling a model** - defining how a models performance should be measured (loss/metrics) as well as defining how it should improve (optimizer).\n",
        "3. **Fitting a model** - letting the model try to find patterns in the data (how does `X` get to `y`).\n",
        "\n",
        "Let's see these in action using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) to build a model for our regression data. And then we'll step through each.\n",
        "\n",
        "> **Note:** If you're using [TensorFlow 2.7.0](https://github.com/tensorflow/tensorflow/releases/tag/v2.7.0)+, the `fit()` function no longer upscales input data to go from `(batch_size, )` to `(batch_size, 1)`. To fix this, you'll need to expand the dimension of input data using `tf.expand_dims(input_data, axis=-1)`.\n",
        ">\n",
        "> In our case, this means instead of using `model.fit(X, y, epochs=5)`, use `model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9jj-OE16yCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014780da-d5c0-4909-cb11-ea269eb07229"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "# model.fit(X, y, epochs=5) # this will break with TensorFlow 2.7.0+\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 6s 6s/step - loss: 19.2976 - mae: 19.2976\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 19.0164 - mae: 19.0164\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 18.7351 - mae: 18.7351\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 18.4539 - mae: 18.4539\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 18.1726 - mae: 18.1726\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00663d2680>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbjCwkEtetB9"
      },
      "source": [
        "Boom!\n",
        "\n",
        "We've just trained a model to figure out the patterns between `X` and `y`.\n",
        "\n",
        "How do you think it went?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWLpG2U3erWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c8763e-b90a-4598-cd09-6a88019b4e17"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZpkaI_Oe6no"
      },
      "source": [
        "What do you think the outcome should be if we passed our model an `X` value of 17.0?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X86cD66Qeo-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8e530b-47e6-414d-90e1-e726cb7b426a"
      },
      "source": [
        "# Make a prediction with the model\n",
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 115ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-16.701845]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YoKIqhffq33"
      },
      "source": [
        "It doesn't go very well... it should've output something close to 27.0.\n",
        "\n",
        "> 🤔 **Question:** What's Keras? I thought we were working with TensorFlow but every time we write TensorFlow code, `keras` comes after `tf` (e.g. `tf.keras.layers.Dense()`)?\n",
        "\n",
        "Before TensorFlow 2.0+, [Keras](https://keras.io/) was an API designed to be able to build deep learning models with ease. Since TensorFlow 2.0+, its functionality has been tightly integrated within the TensorFlow library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAPk1T3xgOm4"
      },
      "source": [
        "## Improving a model\n",
        "\n",
        "How do you think you'd improve upon our current model?\n",
        "\n",
        "If you guessed by tweaking some of the things we did above, you'd be correct.\n",
        "\n",
        "To improve our model, we alter almost every part of the 3 steps we went through before.\n",
        "\n",
        "1. **Creating a model** - here you might want to add more layers, increase the number of hidden units (also called neurons) within each layer, change the activation functions of each layer.\n",
        "2. **Compiling a model** - you might want to choose optimization function or perhaps change the **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - perhaps you could fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from).\n",
        "\n",
        "![various options you can use to improve a neural network model](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/02-improving-a-model-from-model-perspective.png)\n",
        "*There are many different ways to potentially improve a neural network. Some of the most common include: increasing the number of layers (making the network deeper), increasing the number of hidden units (making the network wider) and changing the learning rate. Because these values are all human-changeable, they're referred to as [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) and the practice of trying to find the best hyperparameters is referred to as [hyperparameter tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization).*\n",
        "\n",
        "Woah. We just introduced a bunch of possible steps. The important thing to remember is how you alter each of these will depend on the problem you're working on.\n",
        "\n",
        "And the good thing is, over the next few problems, we'll get hands-on with all of them.\n",
        "\n",
        "For now, let's keep it simple, all we'll do is train our model for longer (everything else will stay the same)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI0LammMgWcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd6fa7a-6ea0-4227-e9e8-48bf4d809fa8"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # train for 100 epochs not 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 604ms/step - loss: 12.9936 - mae: 12.9936\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.8611 - mae: 12.8611\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.7286 - mae: 12.7286\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.5961 - mae: 12.5961\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.4636 - mae: 12.4636\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.3311 - mae: 12.3311\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.1986 - mae: 12.1986\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.0661 - mae: 12.0661\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.9336 - mae: 11.9336\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.8011 - mae: 11.8011\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.6686 - mae: 11.6686\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.5361 - mae: 11.5361\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.4036 - mae: 11.4036\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.2711 - mae: 11.2711\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.1386 - mae: 11.1386\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0061 - mae: 11.0061\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.8736 - mae: 10.8736\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.7411 - mae: 10.7411\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.6086 - mae: 10.6086\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.4761 - mae: 10.4761\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.3436 - mae: 10.3436\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.2111 - mae: 10.2111\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 10.0786 - mae: 10.0786\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.9461 - mae: 9.9461\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8136 - mae: 9.8136\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6811 - mae: 9.6811\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.5486 - mae: 9.5486\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4161 - mae: 9.4161\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2836 - mae: 9.2836\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.1511 - mae: 9.1511\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0186 - mae: 9.0186\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8861 - mae: 8.8861\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7536 - mae: 8.7536\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6211 - mae: 8.6211\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.4886 - mae: 8.4886\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3561 - mae: 8.3561\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.2236 - mae: 8.2236\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.0911 - mae: 8.0911\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9586 - mae: 7.9586\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.8261 - mae: 7.8261\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.6936 - mae: 7.6936\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5611 - mae: 7.5611\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4286 - mae: 7.4286\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2961 - mae: 7.2961\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1700 - mae: 7.1700\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1644 - mae: 7.1644\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1588 - mae: 7.1588\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1531 - mae: 7.1531\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1475 - mae: 7.1475\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1419 - mae: 7.1419\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1363 - mae: 7.1363\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1306 - mae: 7.1306\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1250 - mae: 7.1250\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1194 - mae: 7.1194\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1138 - mae: 7.1138\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1081 - mae: 7.1081\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1025 - mae: 7.1025\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0969 - mae: 7.0969\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0913 - mae: 7.0913\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0856 - mae: 7.0856\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0800 - mae: 7.0800\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0744 - mae: 7.0744\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0688 - mae: 7.0688\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0631 - mae: 7.0631\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0575 - mae: 7.0575\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0519 - mae: 7.0519\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0463 - mae: 7.0463\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0406 - mae: 7.0406\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0350 - mae: 7.0350\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0294 - mae: 7.0294\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0238 - mae: 7.0238\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0181 - mae: 7.0181\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0125 - mae: 7.0125\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0069 - mae: 7.0069\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0013 - mae: 7.0013\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9956 - mae: 6.9956\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9900 - mae: 6.9900\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9844 - mae: 6.9844\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9788 - mae: 6.9788\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9731 - mae: 6.9731\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9675 - mae: 6.9675\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9619 - mae: 6.9619\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9563 - mae: 6.9563\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9506 - mae: 6.9506\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9450 - mae: 6.9450\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9394 - mae: 6.9394\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9338 - mae: 6.9338\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9281 - mae: 6.9281\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9225 - mae: 6.9225\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9169 - mae: 6.9169\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9113 - mae: 6.9113\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9056 - mae: 6.9056\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9000 - mae: 6.9000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8944 - mae: 6.8944\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8888 - mae: 6.8888\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8831 - mae: 6.8831\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8775 - mae: 6.8775\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8719 - mae: 6.8719\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8663 - mae: 6.8663\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8606 - mae: 6.8606\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0065eabcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CIKSm7filgj"
      },
      "source": [
        "You might've noticed the loss value decrease from before (and keep decreasing as the number of epochs gets higher).\n",
        "\n",
        "What do you think this means for when we make a prediction with our model?\n",
        "\n",
        "How about we try predict on 17.0 again?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YcacZsfi4zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6b2301-0c31-447d-9ffe-aff8df8633fb"
      },
      "source": [
        "# Remind ourselves of what X and y are\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvC98q_h6zvG"
      },
      "source": [
        "## Evaluating a model\n",
        "\n",
        "A typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> evaluate it -> build (tweak) a model -> evaulate it -> build (tweak) a model -> evaluate it...\n",
        "```\n",
        "\n",
        "The tweaking comes from maybe not building a model from scratch but adjusting an existing one.\n",
        "\n",
        "### Visualize, visualize, visualize\n",
        "\n",
        "When it comes to evaluation, you'll want to remember the words: \"visualize, visualize, visualize.\"\n",
        "\n",
        "This is because you're probably better looking at something (doing) than you are thinking about something.\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* **The data** - what data are you working with? What does it look like?\n",
        "* **The model itself** - what does the architecture look like? What are the different shapes?\n",
        "* **The training of a model** - how does a model perform while it learns?\n",
        "* **The predictions of a model** - how do the predictions of a model line up against the ground truth (the original labels)?\n",
        "\n",
        "Let's start by visualizing the model.\n",
        "\n",
        "But first, we'll create a little bit of a bigger dataset and a new model we can use (it'll be the same as before, but the more practice the better).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srxuqbeYopns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69ea103-4a9c-44e4-a8b9-fc7e7e54a707"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = np.arange(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQcC0nSko3kJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798785e6-2a92-43aa-b09a-4fc47a7ef5bf"
      },
      "source": [
        "# Make labels for the dataset (adhering to the same pattern as before)\n",
        "y = np.arange(-90, 110, 4)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACgbmrAOpJwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3543a815-2db7-4f22-af64-e7e14e0e2c83"
      },
      "source": [
        "# Same result as above\n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax3MnQDupeBp"
      },
      "source": [
        "## Split data into training/test set\n",
        "\n",
        "One of the other most common and important steps in a machine learning project is creating a training and test set (and when required, a validation set).\n",
        "\n",
        "Each set serves a specific purpose:\n",
        "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available (like the course materials you study during the semester).\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the total data available (like the practice exam you take before the final exam).\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned, it's typically 10-15% of the total data available (like the final exam you take at the end of the semester).\n",
        "\n",
        "For now, we'll just use a training and test set, this means we'll have a dataset for our model to learn on as well as be evaluated on.\n",
        "\n",
        "We can create them by splitting our `X` and `y` arrays.\n",
        "\n",
        "> 🔑 **Note:** When dealing with real-world data, this step is typically done right at the start of a project (the test set should always be kept separate from all other data). We want our model to learn on training data and then evaluate it on test data to get an indication of how well it **generalizes** to unseen examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G0RDMnZrgvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db23e775-8a72-4622-fca7-bd40ba567edd"
      },
      "source": [
        "# Check how many samples we have\n",
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q9ptcQkrGfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164c9b80-9447-4919-a07d-eb52d2a7d425"
      },
      "source": [
        "# Split data into train and test sets\n",
        "X_train = X[:40] # first 40 examples (80% of data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 examples (20% of data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz2cIdECsLH5"
      },
      "source": [
        "## Visualizing the data\n",
        "\n",
        "Now we've got our training and test data, it's a good idea to visualize it.\n",
        "\n",
        "Let's plot it with some nice colours to differentiate what's what."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os30CXBHsOAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "3f07137f-0682-41d3-cb98-0f68eac9792d"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c='b', label='Training data')\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c='g', label='Testing data')\n",
        "# Show the legend\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxRcHZFgtS_B"
      },
      "source": [
        "Beautiful! Any time you can visualize your data, your model, your anything, it's a good idea.\n",
        "\n",
        "With this graph in mind, what we'll be trying to do is build a model which learns the pattern in the blue dots (`X_train`) to draw the green dots (`X_test`).\n",
        "\n",
        "Time to build a model. We'll make the exact same one from before (the one we trained for longer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qpe0eSStSm-"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (same as above)\n",
        "#model.fit(X_train, y_train, epochs=100) # commented out on purpose (not fitting it just yet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gebj2eptqwg8"
      },
      "source": [
        "## Visualizing the predictions\n",
        "\n",
        "Now we've got a trained model, let's visualize some predictions.\n",
        "\n",
        "To visualize predictions, it's always a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Often you'll see this in the form of `y_test` vs. `y_pred` (ground truth vs. predictions).\n",
        "\n",
        "First, we'll make some predictions on the test data (`X_test`), remember the model has never seen the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRzj7LJMYftb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ff5799-23ae-4c4c-bc26-f3d1ad24dffb"
      },
      "source": [
        "# Make predictions\n",
        "y_preds = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hKpW-KOZiAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0bc00f-5906-433b-cb95-7730b29d2ba7"
      },
      "source": [
        "# View the predictions\n",
        "y_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44.544697],\n",
              "       [47.427135],\n",
              "       [50.309574],\n",
              "       [53.192013],\n",
              "       [56.07445 ],\n",
              "       [58.95689 ],\n",
              "       [61.839325],\n",
              "       [64.72176 ],\n",
              "       [67.60421 ],\n",
              "       [70.48664 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPRaFncaZnT-"
      },
      "source": [
        "Okay, we get a list of numbers but how do these compare to the ground truth labels?\n",
        "\n",
        "Let's build a plotting function to find out.\n",
        "\n",
        "> 🔑 **Note:** If you think you're going to be visualizing something a lot, it's a good idea to functionize it so you can use it later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56euC69rZvNJ"
      },
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=y_preds):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot the predictions in red (predictions were made on the test data)\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  # Show the legend\n",
        "  plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fug5_B6Ab7Ah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "dd044464-faf2-4570-fc82-8bd22fb4779b"
      },
      "source": [
        "plot_predictions(train_data=X_train,\n",
        "                 train_labels=y_train,\n",
        "                 test_data=X_test,\n",
        "                 test_labels=y_test,\n",
        "                 predictions=y_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orAfIWOrgRDA"
      },
      "source": [
        "## Evaluating predictions\n",
        "\n",
        "Alongisde visualizations, evaulation metrics are your alternative best option for evaluating your model.\n",
        "\n",
        "Depending on the problem you're working on, different models have different evaluation metrics.\n",
        "\n",
        "Two of the main metrics used for regression problems are:\n",
        "* **Mean absolute error (MAE)** - the mean difference between each of the predictions.\n",
        "* **Mean squared error (MSE)** - the squared mean difference between of the predictions (use if larger errors are more detrimental than smaller errors).\n",
        "\n",
        "The lower each of these values, the better.\n",
        "\n",
        "You can also use [`model.evaluate()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate) which will return the loss of the model as well as any metrics setup during the compile step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPgTdF3ddxiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ee36f3-1f3d-48dd-a4a9-40666798e614"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 132ms/step - loss: 30.4843 - mae: 30.4843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30.484329223632812, 30.484329223632812]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAXIRyVzegFd"
      },
      "source": [
        "In our case, since we used MAE for the loss function as well as MAE for the metrics, `model.evaulate()` returns them both.\n",
        "\n",
        "TensorFlow also has built in functions for MSE and MAE.\n",
        "\n",
        "For many evaluation functions, the premise is the same: compare predictions to the ground truth labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqoMQ0dJeD2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c170104-793b-43c9-dfd3-31bc8264e2e4"
      },
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=y_preds)\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([43.455303, 40.572865, 37.690426, 34.807987, 31.925549, 29.04311 ,\n",
              "       26.160675, 23.278236, 20.39579 , 17.610687], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aJwlTxugPyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d329ceba-d669-4808-c6eb-3dc7388f8cfe"
      },
      "source": [
        "# Check the predictions tensor values (notice the extra square brackets)\n",
        "y_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44.544697],\n",
              "       [47.427135],\n",
              "       [50.309574],\n",
              "       [53.192013],\n",
              "       [56.07445 ],\n",
              "       [58.95689 ],\n",
              "       [61.839325],\n",
              "       [64.72176 ],\n",
              "       [67.60421 ],\n",
              "       [70.48664 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xolZ-lmge_ES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39274fda-255e-4b41-c9ce-fb70faf31cb9"
      },
      "source": [
        "# Check the tensor shapes\n",
        "y_test.shape, y_preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10,), (10, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW1qleu5gHyZ"
      },
      "source": [
        "Remember how we discussed dealing with different input and output shapes is one the most common issues you'll come across, this is one of those times.\n",
        "\n",
        "But not to worry.\n",
        "\n",
        "We can fix it using [`squeeze()`](https://www.tensorflow.org/api_docs/python/tf/squeeze), it'll remove the the `1` dimension from our `y_preds` tensor, making it the same shape as `y_test`.\n",
        "\n",
        "> 🔑 **Note:** If you're comparing two tensors, it's important to make sure they're the right shape(s) (you won't always have to manipulate the shapes, but always be on the look out, *many* errors are the result of mismatched tensors, especially mismatched input and output shapes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVtMyw70g4aF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c542f5ec-1a13-4073-b1a5-e536bd22a4ff"
      },
      "source": [
        "# Shape before squeeze()\n",
        "y_preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnYaBnCng-Nq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2046fd7-6f44-4bae-a8b0-1e8a0d2151f2"
      },
      "source": [
        "# Shape after squeeze()\n",
        "y_preds.squeeze().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxvVeD64hEX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8be73f4-109b-4273-cd2b-12f4b35f2aaa"
      },
      "source": [
        "# What do they look like?\n",
        "y_test, y_preds.squeeze()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106]),\n",
              " array([44.544697, 47.427135, 50.309574, 53.192013, 56.07445 , 58.95689 ,\n",
              "        61.839325, 64.72176 , 67.60421 , 70.48664 ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfUCIeHyhLk7"
      },
      "source": [
        "Okay, now we know how to make our `y_test` and `y_preds` tenors the same shape, let's use our evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvjY6GIJvXBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d9bb98-3585-4295-f85d-1c25e9b3e640"
      },
      "source": [
        "# Calcuate the MAE\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=y_preds.squeeze()) # use squeeze() to make same shape\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=30.48433>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxiD6-QBYSzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40eecb0e-aa23-4c52-ae02-794cc9fd48ce"
      },
      "source": [
        "# Returns the same as tf.metrics.mean_absolute_error()\n",
        "tf.reduce_mean(tf.abs(y_test-y_preds.squeeze()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=30.484329986572266>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmEho4lYofOa"
      },
      "source": [
        "Again, it's a good idea to functionize anything you think you might use over again (or find yourself using over and over again).\n",
        "\n",
        "Let's make functions for our evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs1Z2jgNol5f"
      },
      "source": [
        "def mae(y_test, y_pred):\n",
        "  \"\"\"\n",
        "  Calculuates mean absolute error between y_test and y_preds.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_absolute_error(y_test,\n",
        "                                        y_pred)\n",
        "\n",
        "def mse(y_test, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates mean squared error between y_test and y_preds.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_squared_error(y_test,\n",
        "                                       y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zub5zK7bcl40"
      },
      "source": [
        "## Running experiments to improve a model\n",
        "\n",
        "After seeing the evaluation metrics and the predictions your model makes, it's likely you'll want to improve it.\n",
        "\n",
        "Again, there are many different ways you can do this, but 3 of the main ones are:\n",
        "1. **Get more data** - get more examples for your model to train on (more opportunities to learn patterns).\n",
        "2. **Make your model larger (use a more complex model)** - this might come in the form of more layers or more hidden units in each layer.\n",
        "3. **Train for longer** - give your model more of a chance to find the patterns in the data.\n",
        "\n",
        "Since we created our dataset, we could easily make more data but this isn't always the case when you're working with real-world datasets.\n",
        "\n",
        "So let's take a look at how we can improve our model using 2 and 3.\n",
        "\n",
        "To do so, we'll build 3 models and compare their results:\n",
        "1. `model_1` - same as original model, 1 layer, trained for 100 epochs.\n",
        "2. `model_2` - 2 layers, trained for 100 epochs.\n",
        "3. `model_3` - 2 layers, trained for 500 epochs.\n",
        "\n",
        "**Build `model_1`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StVHIIM9csyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4428341a-7418-4fb8-e6d9-2b312a2a8a24"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate original model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 30.0988 - mae: 30.0988\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4388 - mae: 8.4388\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5960 - mae: 10.5960\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.1312 - mae: 13.1312\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.1970 - mae: 12.1970\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4357 - mae: 9.4357\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5754 - mae: 8.5754\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0484 - mae: 9.0484\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.7568 - mae: 18.7568\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1199 - mae: 10.1199\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4027 - mae: 8.4027\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6692 - mae: 10.6692\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.8023 - mae: 9.8023\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.0152 - mae: 16.0152\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.4080 - mae: 11.4080\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5437 - mae: 8.5437\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.6405 - mae: 13.6405\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4690 - mae: 11.4690\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9154 - mae: 17.9154\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.0500 - mae: 15.0500\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0231 - mae: 11.0231\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1580 - mae: 8.1580\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5191 - mae: 9.5191\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6655 - mae: 7.6655\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.1908 - mae: 13.1908\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.4217 - mae: 16.4217\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.1672 - mae: 13.1672\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.2568 - mae: 14.2568\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0703 - mae: 10.0703\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.3398 - mae: 16.3398\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.6485 - mae: 23.6485\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6261 - mae: 7.6261\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3267 - mae: 9.3267\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.7369 - mae: 13.7369\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.1301 - mae: 11.1301\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.3224 - mae: 13.3224\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4813 - mae: 9.4813\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1438 - mae: 10.1438\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1818 - mae: 10.1818\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.9152 - mae: 10.9152\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9088 - mae: 7.9088\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0967 - mae: 10.0967\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7052 - mae: 8.7052\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.2103 - mae: 12.2103\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.7978 - mae: 13.7978\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4711 - mae: 8.4711\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1381 - mae: 9.1381\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6247 - mae: 10.6247\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7550 - mae: 7.7550\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5461 - mae: 9.5461\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1627 - mae: 9.1627\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.3674 - mae: 16.3674\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.1315 - mae: 14.1315\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.1233 - mae: 21.1233\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.4010 - mae: 16.4010\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9366 - mae: 9.9366\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.6189 - mae: 9.6189\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.9519 - mae: 8.9519\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1374 - mae: 10.1374\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4572 - mae: 8.4572\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3126 - mae: 9.3126\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0772 - mae: 7.0772\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6268 - mae: 8.6268\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2062 - mae: 9.2062\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.4393 - mae: 10.4393\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.7070 - mae: 15.7070\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0863 - mae: 10.0863\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0451 - mae: 9.0451\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.5786 - mae: 12.5786\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.9553 - mae: 8.9553\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9295 - mae: 9.9295\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.9702 - mae: 9.9702\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.4305 - mae: 12.4305\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.5927 - mae: 10.5927\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.6281 - mae: 9.6281\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0915 - mae: 11.0915\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2769 - mae: 8.2769\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9623 - mae: 8.9623\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.8117 - mae: 19.8117\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.8036 - mae: 17.8036\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0915 - mae: 7.0915\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.4045 - mae: 10.4045\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.8260 - mae: 9.8260\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9471 - mae: 7.9471\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4590 - mae: 9.4590\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5023 - mae: 9.5023\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4498 - mae: 11.4498\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9486 - mae: 9.9486\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2579 - mae: 7.2579\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.7103 - mae: 12.7103\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3206 - mae: 7.3206\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.6849 - mae: 7.6849\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1229 - mae: 7.1229\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.5571 - mae: 12.5571\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9330 - mae: 9.9330\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1413 - mae: 9.1413\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.0806 - mae: 12.0806\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0788 - mae: 9.0788\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4999 - mae: 8.4999\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.4517 - mae: 14.4517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0065a91180>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Da56xspOrY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "c468a93c-d7ed-4274-8ad7-a3c7c62e9efc"
      },
      "source": [
        "2# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXxHBAtHoSh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a48914-c28c-4aae-cc1c-aa2adfd94b8c"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "mae_1 = mae(y_test, y_preds_1.squeeze()).numpy()\n",
        "mse_1 = mse(y_test, y_preds_1.squeeze()).numpy()\n",
        "mae_1, mse_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30.638134, 949.13086)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXELOpdBrE9_"
      },
      "source": [
        "**Build `model_2`**\n",
        "\n",
        "This time we'll add an extra dense layer (so now our model will have 2 layers) whilst keeping everything else the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05vcgEP3rEFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d3aede-85f2-4670-f1d0-168065fdec1b"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate model_1 and add an extra layer\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1) # add a second layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0) # set verbose to 0 for less output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00643ba560>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xCbDcoDraux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "322c6548-42c1-42ec-8680-3a1e649a9607"
      },
      "source": [
        "# Make and plot predictions for model_2\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f006436f880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxMYu5Frri6o"
      },
      "source": [
        "Woah, that's looking better already! And all it took was an extra layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LnPuGaBrcrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f30e96-4218-45cd-8539-a18198dde62c"
      },
      "source": [
        "# Calculate model_2 metrics\n",
        "mae_2 = mae(y_test, y_preds_2.squeeze()).numpy()\n",
        "mse_2 = mse(y_test, y_preds_2.squeeze()).numpy()\n",
        "mae_2, mse_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10.610324, 120.35542)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8i9yfQGrwHx"
      },
      "source": [
        "**Build `model_3`**\n",
        "\n",
        "For our 3rd model, we'll keep everything the same as `model_2` except this time we'll train for longer (500 epochs instead of 100).\n",
        "\n",
        "This will give our model more of a chance to learn the patterns in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABGwQFsbrvUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e29c0e-bf45-4332-94a0-7a02e2d4f9b2"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate model_2\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model (this time for 500 epochs, not 100)\n",
        "model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500, verbose=0) # set verbose to 0 for less output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0065a5c8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEz4bVmasbFk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "27d67368-f794-4a6d-e508-59c60458fd77"
      },
      "source": [
        "# Make and plot predictions for model_3\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00641280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 55ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38Ki8ZHcsztG"
      },
      "source": [
        "Strange, we trained for longer but our model performed worse?\n",
        "\n",
        "As it turns out, our model might've trained too long and has thus resulted in worse results (we'll see ways to prevent training for too long later on)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTUcFe4sbfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e867a61-9fc2-4fbb-e193-63fb44fc643d"
      },
      "source": [
        "# Calculate model_3 metrics\n",
        "mae_3 = mae(y_test, y_preds_3.squeeze()).numpy()\n",
        "mse_3 = mse(y_test, y_preds_3.squeeze()).numpy()\n",
        "mae_3, mse_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67.224594, 4601.822)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPEeM3UsrxGB"
      },
      "source": [
        "## Comparing results\n",
        "\n",
        "Now we've got results for 3 similar but slightly different results, let's compare them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw5RZk-BqLZd"
      },
      "source": [
        "model_results = [[\"model_1\", mae_1, mse_1],\n",
        "                 [\"model_2\", mae_2, mse_2],\n",
        "                 [\"model_3\", mae_3, mae_3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip7bKH83p5X0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8783303f-53d2-44d3-a66c-f1bfec3b399e"
      },
      "source": [
        "import pandas as pd\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
        "all_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     model        mae         mse\n",
              "0  model_1  30.638134  949.130859\n",
              "1  model_2  10.610324  120.355423\n",
              "2  model_3  67.224594   67.224594"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d298273-e93f-4ed5-9464-20e305f077e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>30.638134</td>\n",
              "      <td>949.130859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>10.610324</td>\n",
              "      <td>120.355423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>67.224594</td>\n",
              "      <td>67.224594</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d298273-e93f-4ed5-9464-20e305f077e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d298273-e93f-4ed5-9464-20e305f077e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d298273-e93f-4ed5-9464-20e305f077e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe5DgNbX6192"
      },
      "source": [
        "## Saving a model\n",
        "\n",
        "Once you've trained a model and found one which performs to your liking, you'll probably want to save it for use elsewhere (like a web application or mobile device).\n",
        "\n",
        "You can save a TensorFlow/Keras model using [`model.save()`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model).\n",
        "\n",
        "There are two ways to save a model in TensorFlow:\n",
        "1. The [SavedModel format](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format) (default).\n",
        "2. The [HDF5 format](https://www.tensorflow.org/tutorials/keras/save_and_load#hdf5_format).\n",
        "\n",
        "The main difference between the two is the SavedModel is automatically able to save custom objects (such as special layers) without additional modifications when loading the model back in.\n",
        "\n",
        "Which one should you use?\n",
        "\n",
        "It depends on your situation but the SavedModel format will suffice most of the time.\n",
        "\n",
        "Both methods use the same method call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg0jD2cUoPsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261f2136-244e-40da-9aab-51b629b8e2ca"
      },
      "source": [
        "# Save a model using the SavedModel format\n",
        "model_2.save('best_model_SavedModel_format')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsCpDYrU7D1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b3eb4b-b4e8-4f1d-d86f-714d10708981"
      },
      "source": [
        "# Check it out - outputs a protobuf binary file (.pb) as well as other files\n",
        "!ls best_model_SavedModel_format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\tfingerprint.pb\tkeras_metadata.pb  saved_model.pb  variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97J6GJMBSM2j"
      },
      "source": [
        "# Save a model using the HDF5 format\n",
        "model_2.save(\"best_model_HDF5_format.h5\") # note the addition of '.h5' on the end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGA02tY97EUI"
      },
      "source": [
        "## Loading a model\n",
        "\n",
        "We can load a saved model using the [`load_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model) method.\n",
        "\n",
        "Loading a model for the different formats (SavedModel and HDF5) is the same (as long as the pathnames to the particular formats are correct)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzyLIWfs7Fvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1e3965-fe8f-49fd-ce96-a55f39734ca7"
      },
      "source": [
        "# Load a model from the SavedModel format\n",
        "loaded_saved_model = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n",
        "loaded_saved_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABtsYBDtr5Zz"
      },
      "source": [
        "## Downloading a model (from Google Colab)\n",
        "\n",
        "Say you wanted to get your model from Google Colab to your local machine, you can do one of the following things:\n",
        "* Right click on the file in the files pane and click 'download'.\n",
        "* Use the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV0onjIIr9XC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "96827c1d-68a4-4823-bccb-c9f8b7299c25"
      },
      "source": [
        "# Download the model (or any file) from Google Colab\n",
        "from google.colab import files\n",
        "files.download(\"best_model_HDF5_format.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_70fb08d7-6b9f-455b-8282-a93170225ab0\", \"best_model_HDF5_format.h5\", 21952)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add more from\n",
        "https://github.com/mrdbourke/tensorflow-deep-learning/tree/main\n",
        "\n",
        "https://dev.mrdbourke.com/tensorflow-deep-learning/"
      ],
      "metadata": {
        "id": "0X44HnhcwuwP"
      }
    }
  ]
}